# 操作系统面试题

## **什么是操作系统？**

操作系统是管理硬件和软件的一种应用程序。操作系统是运行在计算机上最重要的一种 `软件`，它管理计算机的资源和进程以及所有的硬件和软件。它为计算机硬件和软件提供了一种中间层，使应用软件和硬件进行分离，让我们无需关注硬件的实现，把关注点更多放在软件应用上。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101744677.png)

通常情况下，计算机上会运行着许多应用程序，它们都需要对内存和 CPU 进行交互，操作系统的目的就是为了保证这些访问和交互能够准确无误的进行。

## **操作系统的主要功能**

一般来说，现代操作系统主要提供下面几种功能：

- `进程管理`: 进程管理的主要作用就是任务调度，在单核处理器下，操作系统会为每个进程分配一个任务，进程管理的工作十分简单；而在多核处理器下，操作系统除了要为进程分配任务外，还要解决处理器的调度、分配和回收等问题
- `内存管理`：内存管理主要是操作系统负责管理内存的分配、回收，在进程需要时分配内存以及在进程完成时回收内存，协调内存资源，通过合理的页面置换算法进行页面的换入换出
- `设备管理`：根据确定的设备分配原则对设备进行分配，使设备与主机能够并行工作，为用户提供良好的设备使用界面。
- `文件管理`：有效地管理文件的存储空间，合理地组织和管理文件系统，为文件访问和文件保护提供更有效的方法及手段。
- `提供用户接口`：操作系统提供了访问应用程序和硬件的接口，使用户能够通过应用程序发起系统调用从而控制硬件，实现想要的功能。

<table>
    <tr>
    <td> 功能模块 <br/></td><td> 核心职责 <br/></td><td> 关键机制 <br/></td><td> 典型场景 <br/></td></tr>
    <tr>
    <td> 进程管理 <br/></td><td>1. 任务调度（CPU时间片分配）<br/>2. 多核处理器负载均衡<br/>3. 进程创建/销毁/同步<br/></td><td>- 时间片轮转（Round-Robin）<br/>- 优先级调度<br/>- 多级反馈队列（MLFQ）<br/></td><td>单核CPU分时运行多个程序；服务器多核任务分配<br/></td></tr>
    <tr>
    <td> 内存管理 <br/></td><td>1. 内存分配与回收<br/>2. 虚拟内存管理<br/>3. 页面置换优化<br/></td><td>- 分页/分段机制<br/>- LRU/FIFO页面置换算法<br/>- 内存映射（MMAP）<br/></td><td>程序运行时动态申请内存；解决内存不足问题<br/></td></tr>
    <tr>
    <td> 设备管理 <br/></td><td>1. 设备驱动控制<br/>2. 并行/串行I/O调度<br/>3. 即插即用（PnP）支持<br/></td><td>- 中断机制<br/>- DMA传输<br/>- 设备文件抽象（如Linux `/dev`）<br/></td><td>打印机队列管理；USB设备热插拔识别<br/></td></tr>
    <tr>
    <td> 文件管理 <br/></td><td>1. 存储空间分配<br/>2. 文件系统组织<br/>3. 权限与保护机制<br/></td><td>- FAT/NTFS/EXT4文件系统<br/>- 索引节点（inode）<br/>- 日志式写入（Journaling）<br/></td><td>磁盘文件读写；多用户共享文件权限控制<br/></td></tr>
    <tr>
    <td> 用户接口 <br/></td><td>1. 提供系统调用（Syscall）<br/>2. 图形界面（GUI）或命令行（CLI）<br/></td><td>- Shell解释器（Bash/Zsh）<br/>- WinAPI/POSIX标准<br/>- 桌面环境（如GNOME/KDE）<br/></td><td>用户通过终端命令或点击图标启动应用程序<br/></td></tr>
    </table>



## **🌟 软件访问硬件的几种方式**

软件访问硬件其实就是一种 I/O 操作，软件访问硬件的方式，也就是 I/O 操作的方式有哪些。

硬件在 I/O 上大致分为**并行和串行**，同时也对应串行接口和并行接口。

随着计算机技术的发展，I/O 控制方式也在不断发展。选择和衡量 I/O 控制方式有如下三条原则：

1. 数据传送速度足够快，能满足用户的需求但又不丢失数据；
2. 系统开销小，所需的处理控制程序少；
3. 能充分发挥硬件资源的能力，使 I/O 设备尽可能忙，而 CPU 等待时间尽可能少。

根据以上控制原则，I/O 操作可以分为四类：

- `直接访问`：直接访问由用户进程直接控制主存或 CPU 和外围设备之间的信息传送。直接程序控制方式又称为忙/等待方式。
- `中断驱动`：为了减少程序直接控制方式下 CPU 的等待时间以及提高系统的并行程度，系统引入了中断机制。中断机制引入后，外围设备仅当操作正常结束或异常结束时才向 CPU 发出中断请求。在 I/O 设备输入每个数据的过程中，由于无需 CPU 的干预，一定程度上实现了 CPU 与 I/O 设备的并行工作。

上述两种方法的特点都是以 `CPU` 为中心，数据传送通过一段程序来实现，软件的传送手段限制了数据传送的速度。接下来介绍的这两种 I/O 控制方式采用硬件的方法来显示 I/O 的控制

- `DMA 直接内存访问`：为了进一步减少 CPU 对 I/O 操作的干预，防止因并行操作设备过多使 CPU 来不及处理或因速度不匹配而造成的数据丢失现象，引入了 DMA 控制方式。
- `通道控制方式`：通道是独立于 CPU 的专门负责输入输出控制的处理机，它控制设备与内存直接进行数据交换。有自己的通道指令，这些指令由 CPU 启动，并在操作结束时向 CPU 发出中断信号。

<table>
    <tr>
    <td> I/O控制方式 <br/></td><td> 工作原理 <br/></td><td> CPU参与度 <br/></td><td> 数据传输速度 <br/></td></tr>
    <tr>
    <td> 直接访问 <br/></td><td>用户进程直接控制I/O操作，CPU轮询设备状态（忙等待）<br/></td><td>100%<br/></td><td>最慢<br/></td></tr>
    <tr>
    <td> 中断驱动 <br/></td><td>设备就绪后向CPU发送中断信号，CPU处理中断<br/></td><td>中等<br/></td><td>较慢<br/></td></tr>
    <tr>
    <td> DMA <br/></td><td>由DMA控制器直接管理设备与内存的数据传输，完成后通知CPU<br/></td><td>极低<br/></td><td>快<br/></td></tr>
    <tr>
    <td> 通道控制 <br/></td><td>专用I/O处理器（通道）独立执行I/O程序，完全解放CPU<br/></td><td>几乎不参与<br/></td><td>最快<br/></td></tr>
    </table>



## **🌟 操作系统的主要目的是什么？**

操作系统是一种软件，它的主要目的有三种

- 管理计算机资源，这些资源包括 CPU、内存、磁盘驱动器、打印机等。
- 提供一种图形界面，就像我们前面描述的那样，它提供了用户和计算机之间的桥梁。
- 为其他软件提供服务，操作系统与软件进行交互，以便为其分配运行所需的任何必要资源。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101744992.png)

## **操作系统的种类有哪些？**

常见的操作系统只有三种：**Windows、macOS 和 Linux**。

## **🌟 为什么 Linux 系统下的应用程序不能直接在 Windows 下运行？**

这是一个老生常谈的问题了，在这里给出具体的回答。

其中一点是因为 Linux 系统和 Windows 系统的格式不同，**格式就是协议**，就是在固定位置有意义的数据。Linux 下的可执行程序文件格式是 `elf`，可以使用 `readelf` 命令查看 elf 文件头。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101744249.png)

而 Windows 下的可执行程序是 `PE` 格式，它是一种可移植的可执行文件。

还有一点是因为 Linux 系统和 Windows 系统的 `API` 不同，这个 API 指的就是操作系统的 API，Linux 中的 API 被称为 `系统调用`，是通过 `int 0x80` 这个软中断实现的。而 Windows 中的 API 是放在动态链接库文件中的，也就是 Windows 开发人员所说的 `DLL` ，这是一个库，里面包含代码和数据。Linux 中的可执行程序获得系统资源的方法和 Windows 不一样，所以显然是不能在 Windows 中运行的。

<table>
    <tr>
    <td>对比项<br/></td><td>Linux 系统<br/></td><td>Windows 系统<br/></td></tr>
    <tr>
    <td> 可执行文件格式 <br/></td><td>ELF (Executable and Linkable Format)<br/></td><td>PE (Portable Executable)<br/></td></tr>
    <tr>
    <td> 查看工具 <br/></td><td>`readelf`、`objdump`<br/></td><td>`dumpbin`（Visual Studio 工具）、PE 查看器<br/></td></tr>
    <tr>
    <td> 文件结构特点 <br/></td><td>分段结构（如 `.text`、`.data`、`.rodata`），支持动态链接（`.so` 文件）<br/></td><td>分节结构（如 `.text`、`.rdata`），依赖动态链接库（DLL 文件）<br/></td></tr>
    <tr>
    <td> 系统 API 实现 <br/></td><td>通过 `int 0x80` 或 `syscall` 指令触发系统调用（如 `read`, `write`）<br/></td><td>通过 DLL 导出 API（如 `kernel32.dll`、`user32.dll` 中的函数）<br/></td></tr>
    <tr>
    <td> 资源访问方式 <br/></td><td>直接调用内核提供的系统调用接口<br/></td><td>调用 Windows API 封装层，再由内核处理<br/></td></tr>
    <tr>
    <td> 兼容层原理 <br/></td><td>WINE 通过将 Linux 系统调用转换为 Windows API 调用实现部分兼容<br/></td><td>WSL 通过虚拟化层模拟 Linux 内核行为<br/></td></tr>
    <tr>
    <td> 典型限制 <br/></td><td>依赖 Linux 特有的库（如 `glibc`）和路径结构（如 `/proc`）<br/></td><td>依赖 Windows 注册表、DLL 版本和运行时环境（如 Visual C++ Redistributable）<br/></td></tr>
    </table>



## **🌟**什么是用户态？什么是内核态？

`内核态`：又指管态、系统态，是操作系统**管理程序执行时**机器所处的状态。具有较高特权，能执行一切指令。

`用户态`：是用户程序执行时机器所处的状态，特权较低，只能执行规定内的指令，访问指定的部分。

总结：内核态特权高，可以横行霸道，拥有一切特权，执行指令，访问内存。用户态特权小，只能执行部分指令，访问部分内存。

另外**用户不能直接调用内核态程序，只能通过中断，由中断系统将其转入操作系统内的相应程序。**

`特权指令`：只能有操作系统内核部分使用，不允许用户直接使用的指令，I/0 指令。设置中断屏蔽指令、清内存指令，存储保护指令，设置时钟指令。

## 中断和异常

`中断`：又称为外中断，是系统正常功能的一部分，使系统停止当前运行的进程而执行其他进程。然后操作系统处理完该任务之后，再来处理中断前的命令。

`异常`：是由错误引起的，如文件损坏、进程越界等。

## **为什么称为陷入内核？**

如果把软件结构进行分层说明的话，应该是这个样子的，最外层是应用程序，里面是操作系统内核。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101743853.png)

应用程序处于特权级 3，操作系统内核处于特权级 0 。如果用户程序想要访问操作系统资源时，会发起系统调用，陷入内核，这样 CPU 就进入了内核态，执行内核代码。至于为什么是陷入，我们看图，内核是一个凹陷的构造，有陷下去的感觉，所以称为陷入。

## **🌟 用户态和内核态是如何切换的？**

所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种模式下的转换，即**用户态 -> 内核态 -> 用户态**，而唯一能够做这些操作的只有 `系统调用`，而能够执行系统调用的就只有 `操作系统`。

一般用户态到内核态的转换我们都称之为 trap 进内核，也被称之为 `陷阱指令(trap instruction)`。

它们的工作流程如下：

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101743165.png)

- 首先用户程序会调用 `glibc` 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。
- glibc 库知道针对不同体系结构调用 `系统调用` 的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。
- 然后，glibc 库调用 `软件中断指令(SWI)` ，这个指令通过更新 `CPSR` 寄存器将模式改为超级用户模式，然后跳转到地址 `0x08` 处。
- 到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问
- 从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 `vector_swi()`。
- 在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 `sys_call_table` 的索引，调转到系统调用函数。
- 执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。

<table>
<tr>
<td>步骤<br/></td><td>用户态操作<br/></td><td>内核态操作<br/></td><td>关键点说明<br/></td></tr>
<tr>
<td>1<br/></td><td>用户程序调用 `glibc` 库的 API（如 `read()`）<br/></td><td>-<br/></td><td>`glibc` 封装系统调用，提供标准化接口<br/></td></tr>
<tr>
<td>2<br/></td><td>`glibc` 根据体系结构设置参数（如 x86-64 用 `rax` 存系统调用号）<br/></td><td>-<br/></td><td>参数传递规则由 ABI（应用二进制接口）定义<br/></td></tr>
<tr>
<td>3<br/></td><td>执行陷阱指令（x86: `syscall`/`int 0x80`，ARM: `SWI`，RISC-V: `ecall`）<br/></td><td>CPU 切换到内核模式（修改 CPSR/EFLAGS 寄存器）<br/></td><td>硬件自动完成模式切换，跳转到固定中断向量地址（如 x86: `0x80`，ARM: `0x08`）<br/></td></tr>
<tr>
<td>4<br/></td><td>-<br/></td><td>MMU 启用内核内存映射，允许访问内核空间<br/></td><td>内核页表包含用户空间映射，但用户页表无内核映射<br/></td></tr>
<tr>
<td>5<br/></td><td>-<br/></td><td>执行中断处理程序（x86: `system_call()`，ARM: `vector_swi()`）<br/></td><td>通过系统调用号索引 `sys_call_table` 找到具体实现<br/></td></tr>
<tr>
<td>6<br/></td><td>-<br/></td><td>内核执行系统调用（如 `sys_read()`），访问硬件或核心资源<br/></td><td>期间可能阻塞（如等待磁盘 I/O）<br/></td></tr>
<tr>
<td>7<br/></td><td>-<br/></td><td>内核将结果存入寄存器/栈，恢复用户态寄存器<br/></td><td>错误码通常通过 `errno` 机制返回<br/></td></tr>
<tr>
<td>8<br/></td><td>CPU 切换回用户模式，继续执行 `glibc` 返回后的代码<br/></td><td>-<br/></td><td>用户程序通过返回值判断成功/失败<br/></td></tr>
</table>


### 关键概念对比

<table>
    <tr>
    <td>对比维度<br/></td><td>用户态 (User Mode)<br/></td><td>内核态 (Kernel Mode)<br/></td></tr>
    <tr>
    <td> 权限级别 <br/><br/></td><td>受限权限（无法直接访问硬件）<br/></td><td>特权模式（可执行任意CPU指令）<br/></td></tr>
    <tr>
    <td> 内存访问 <br/></td><td>仅能访问用户空间内存<br/></td><td>可访问全部物理内存和IO设备<br/></td></tr>
    <tr>
    <td> 触发方式 <br/></td><td>通过调用库函数（如`glibc`）<br/></td><td>通过陷阱指令（`syscall`/`int 0x80`）主动进入<br/></td></tr>
    <tr>
    <td> 典型场景 <br/></td><td>应用程序逻辑运算<br/></td><td>硬件交互、进程调度、中断处理<br/></td></tr>
    </table>



## **什么是内核？**

**在计算机中，内核是一个计算机程序，它是操作系统的核心，可以控制操作系统中所有的内容**。内核通常是在 `boot loader` 装载程序之前加载的第一个程序。

这里还需要了解一下什么是 `boot loader`。

> boot loader 又被称为引导加载程序，能够将计算机的操作系统放入内存中。在电源通电或者计算机重启时，BIOS 会执行一些初始测试，然后将控制权转移到引导加载程序所在的**主引导记录(MBR)** 。

## Linux 操作系统启动流程

- [Linux 操作系统启动流程梳理 - 散尽浮华 - 博客园](https://www.cnblogs.com/kevingrace/p/6244584.html)
- [https://cloud.tencent.com/developer/article/1114481](https://cloud.tencent.com/developer/article/1114481)

## 什么是系统调用？

介绍系统调用之前，我们先来了解一下用户态和系统态。

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1. 用户态(user mode) : 用户态运行的进程或可以直接读取用户程序的数据。
2. 系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

说了用户态和系统态之后，那么什么是系统调用呢？

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！

也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

- 设备管理。完成设备的请求或释放，以及设备启动等功能。
- 文件管理。完成文件的读、写、创建及删除等功能。
- 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
- 进程通信。完成进程之间的消息传递或信号传递等功能。
- 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

<table>
    <tr>
    <td>对比维度<br/></td><td>用户态 (User Mode)<br/></td><td>内核态 (Kernel Mode)<br/></td></tr>
    <tr>
    <td> 权限级别 <br/><br/></td><td>受限权限（无法直接访问硬件）<br/></td><td>特权模式（可执行任意CPU指令）<br/></td></tr>
    <tr>
    <td> 内存访问 <br/></td><td>仅能访问用户空间内存<br/></td><td>可访问全部物理内存和IO设备<br/></td></tr>
    <tr>
    <td> 触发方式 <br/></td><td>通过调用库函数（如`glibc`）<br/></td><td>通过陷阱指令（`syscall`/`int 0x80`）主动进入<br/></td></tr>
    <tr>
    <td> 典型场景 <br/></td><td>应用程序逻辑运算<br/></td><td>硬件交互、进程调度、中断处理<br/></td></tr>
    </table>



# 进程管理篇

## 进程与线程

### **🌟**什么是进程？

**标准定义：**进程是一个具有一定独立功能的程序在一个数据集合上依次动态执行的过程。进程是一个正在执行程序的实例，包括程序计数器、寄存器和程序变量的当前值。

简单来说**进程就是一个程序的执行流程，内部保存程序运行所需的资源**。

在操作系统中可以有多个进程在运行，可对于 CPU 来说，同一时刻，一个 CPU 只能运行一个进程，但在某一时间段内，CPU 将这一时间段拆分成更短的时间片，CPU 不停的在各个进程间游走，这就给人一种并行的错觉，像 CPU 可以同时运行多个进程一样，这就是伪并行。

<table>
    <tr>
    <td>对比维度<br/></td><td>进程 (Process)<br/></td><td>程序 (Program)<br/></td></tr>
    <tr>
    <td> 本质 <br/></td><td>程序的 动态执行实例 <br/></td><td>存储在磁盘上的 静态可执行文件 <br/></td></tr>
    <tr>
    <td> 生命周期 <br/></td><td>有创建、运行、阻塞、终止等状态变化<br/></td><td>无生命周期概念（除非被加载为进程）<br/></td></tr>
    <tr>
    <td> 资源占用 <br/></td><td>独立分配内存、文件描述符、CPU时间片等系统资源<br/></td><td>不占用实际资源（仅占用磁盘空间）<br/></td></tr>
    <tr>
    <td> 并发性 <br/></td><td>多个进程可并发执行（伪并行/真并行）<br/></td><td>无法并发（需被加载为进程才能运行）<br/></td></tr>
    <tr>
    <td> 组成结构 <br/></td><td>包含代码段、数据段、堆、栈、PCB（进程控制块）<br/></td><td>仅包含代码段、数据段等静态内容<br/></td></tr>
    </table>



#### **主要特点**

- 动态性：进程是程序的一次执行过程，它是动态地产生、变化和消亡的。一个程序可以多次被执行，每次执行都会创建一个新的进程。
- 独立性：每个进程都有自己独立的地址空间，不同进程之间的内存空间是相互隔离的。这意味着一个进程中的错误不会影响到其他进程。
- 并发性：在多道程序设计系统中，多个进程可以同时存在并执行。操作系统通过时间片轮转等调度算法，在不同进程之间切换执行，从而实现并发执行。
- 制约性：因访问共享资源或进程间同步而产生制约。

#### **组成部分**

- 程序代码：进程执行的指令序列，是进程的静态部分。
- 数据：进程在执行过程中所使用的变量、常量、数组等数据，也是进程的静态部分。
- 进程控制块（PCB）：是操作系统为了管理进程而设置的数据结构，包含了进程的标识信息、状态信息、资源信息等。PCB 是进程存在的唯一标志，操作系统通过 PCB 来对进程进行管理和调度。

#### **重要作用**

- 资源分配：操作系统通过为进程分配资源，如内存、CPU 时间、文件等，来实现对计算机系统资源的有效管理和利用。
- 提高系统效率：通过并发执行多个进程，可以充分利用计算机的硬件资源，提高系统的效率和吞吐量。
- 实现多任务处理：在现代操作系统中，用户可以同时运行多个应用程序，每个应用程序都是一个进程。操作系统通过对进程的管理和调度，实现了多任务处理，提高了用户的工作效率。

### 进程和程序有什么联系？

一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。

- 程序是产生进程的基础
- 程序的每次运行产生不同的进程
- 进程是程序功能的体现
- 通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序

### **🌟**进程和程序的区别？

- **进程是动态的，程序是静态的**：程序是有序代码的集合，进程是程序的执行。
- **进程是暂时的，程序是永久的**：进程是一个状态变化的过程，程序可长久保存。
- **进程和程序的组成不同**：进程的组成包括程序、数据和进程控制块（进程状态信息）。

<table>
    <tr>
    <td> 对比维度 <br/></td><td> 进程 (Process) <br/></td><td> 程序 (Program) <br/></td></tr>
    <tr>
    <td> 本质 <br/></td><td>程序的 动态执行实例 <br/></td><td>静态的 代码和数据集合 <br/></td></tr>
    <tr>
    <td> 存在形式 <br/></td><td>运行时存在于内存中<br/></td><td>永久存储在磁盘上<br/></td></tr>
    <tr>
    <td> 生命周期 <br/></td><td>临时（创建→运行→终止）<br/></td><td>永久（除非被删除）<br/></td></tr>
    <tr>
    <td> 组成结构 <br/></td><td>程序代码 + 数据 + 堆栈 + PCB（进程控制块）<br/></td><td>仅包含代码段、数据段等静态内容<br/></td></tr>
    <tr>
    <td> 资源占用 <br/></td><td>分配CPU、内存、文件描述符等运行时资源<br/></td><td>仅占用磁盘存储空间<br/></td></tr>
    <tr>
    <td> 状态变化 <br/></td><td>有运行、就绪、阻塞等状态<br/></td><td>无状态概念<br/></td></tr>
    <tr>
    <td> 独立性 <br/></td><td>拥有独立的内存地址空间<br/></td><td>必须被加载为进程才能运行<br/></td></tr>
    <tr>
    <td> 并发性 <br/></td><td>多个进程可并发执行<br/></td><td>无法直接并发<br/></td></tr>
    <tr>
    <td> 创建方式 <br/></td><td>通过`fork()`/`exec()`或`CreateProcess()`生成<br/></td><td>由开发者编写并编译/解释保存<br/></td></tr>
    <tr>
    <td> 是否直接操作硬件 <br/></td><td>通过系统调用间接操作<br/></td><td>不涉及硬件操作<br/></td></tr>
    </table>



### 如何创建进程？

有什么事件会触发进程的创建呢？

- **系统初始化**：当启动操作系统时，通常会创建很多进程，有些是同用户交互并替他们完成工作的前台进程，其它的都是后台进程，后台进程和特定用户没有关系，但也提供某些专门的功能，例如接收邮件等，这种功能的进程也称为守护进程。计划任务是个典型的守护进程，它每分钟运行一次来检查是否有工作需要它完成。如果有工作要做，它就会完成此工作，然后进入休眠状态，直到下一次检查时刻的到来。
- **正在运行的程序执行了创建进程的系统调用**：在一个进程中又创建了一个新的进程，这种情况很常见。
- **用户请求创建一个新进程**：这种情况相信每个人都见过，用电脑时双击某个应用图标，就会有至少一个进程被创建。
- **一个批处理作业的初始化**：这种情形不常见，仅在大型机的批处理系统中应用，用户在这种系统中提交批处理作业，在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。

归根到底：在 UNIX 系统中，只有 fork 系统调用才可以创建新进程，使用方式如下：

```cpp
#include <stdio.h>
#include <unistd.h>
int main() {
    pid_t id = fork();
    if (id < 0) {
        perror("fork\n");
    } else if (id == 0) {  // 子进程
        printf("子进程\n");
    } else {  // 父进程
       printf("父进程\n");
   }
   return 0;
}
```

进程创建之后，父子进程都有**各自不同的地址空间**，其中一个进程在其地址空间的修改对另一个进程不可见。子进程的初始化空间是父进程的一个副本，这里涉及两个不同地址空间，不可写的内存区是共享的，某些 UNIX 的实现使程序正文在两者间共享，因为它是不可修改的。

### 进程为何终止？

有什么事件会触发进程的终止呢？

- **正常退出**（自愿）：进程完成了工作正常终止，UNIX 中退出进程的系统调用是 exit。
- **出错退出**（自愿）：进程发现了错误而退出。可以看如下代码：

```cpp
#include <stdio.h>
#include <stdlib.h>
void Func() {
    if (error) { // 有错误就退出程序
        exit(1);
    }
}

int main() {
    Func();
}
```

- **严重错误**（非自愿）：进程发生了严重的错误而不得不退出，通常是程序的错误导致，例如执行了一条非法指令，引用不存在的内存，或者除数是 0 等，出现这些错误时进程默认会退出。而有些时候如果用户想自行处理某种类型的错误，发生不同类型错误时进程会收到不同类型的信号，用户注册处理不同信号的函数即可。
- **被其它进程杀死**（非自愿）：其它进程执行 kill 系统调用通知操作系统杀死某个进程。

### **🌟**操作系统如何进行进程管理？

这里就不得不提到一个数据结构：进程控制块（PCB），**操作系统为每个进程都维护一个 PCB**，用来保存与该进程有关的各种状态信息。进程可以抽象理解为就是一个 PCB，**PCB 是进程存在的唯一标志**，操作系统用 PCB 来描述进程的基本情况以及运行变化的过程，进程的任何状态变化都会通过 PCB 来体现。

**PCB 包含进程状态的重要信息**，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其它在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未中断过一样。

提到进程管理，有一个概念我们必须要知道，就是**中断向量**，中断向量是指中断服务程序的入口地址。一个进程在执行过程中可能会被中断无数次，但是每次中断后，被中断的进程都要返回到与中断发生前完全相同的状态。

中断发生后操作系统底层做了什么？

1. 硬件压入堆栈程序计数器等；
2. 硬件从中断向量装入新的程序计数器；
3. 汇编语言过程保存寄存器值；
4. 汇编语言过程设置新的堆栈；
5. C 中断服务例程运行（典型的读和缓冲输入）；
6. 调度程序决定下一个将运行的进程；
7. C 过程返回到汇编代码；
8. 汇编语言过程开始运行新的当前进程。

## 📚 关键补充说明

```c
// Linux 中 PCB 的简化结构（task_struct 部分字段）
struct task_struct {
    volatile long state;          // 进程状态（-1不可运行, 0可运行, >0已停止）
    struct mm_struct *mm;         // 内存管理信息
    pid_t pid;                    // 进程标识符
    struct files_struct *files;   // 打开的文件表
    struct thread_struct thread;  // CPU 寄存器状态
    // ... 其他 100+ 字段
};
```

### 为什么说 PCB（进程控制块）是进程存在的唯一标识？

PCB（进程控制块）是操作系统中用来管理和控制进程的数据结构，其中包含了进程的各种信息，如进程状态、程序计数器、寄存器、内存分配情况、打开文件列表等。由于 PCB 包含了进程的所有关键信息，因此可以说 PCB 是进程存在的唯一标识。

主要存储这些信息：

- **进程标识信息**：如本进程的标识，本进程的父进程标识，用户标识等。
- **处理机状态信息保护区**：用于保存进程的运行现场信息：

  - 用户可见寄存器：用户程序可以使用的数据，地址等寄存器
  - 控制和状态寄存器：程序计数器，程序状态字
  - 栈指针：过程调用、系统调用、中断处理和返回时需要用到它
- **进程控制信息**：

  - 调度和状态信息：用于操作系统调度进程使用
  - 进程间通信信息：为支持进程间与通信相关的各种标识、信号、信件等，这些信息存在接收方的进程控制块中
  - 存储管理信息：包含有指向本进程映像存储空间的数据结构
  - 进程所用资源：说明由进程打开使用的系统资源，如打开的文件等
  - 有关数据结构连接信息：进程可以连接到一个进程队列中，或连接到相关的其他进程的 PCB

每个进程都有一个独特的 PCB，通过 PCB 可以唯一地标识和管理每个进程。当操作系统需要对一个进程进行调度、切换或终止时，就需要通过该进程对应的 PCB 来获取和修改进程的相关信息。

因此，可以说 PCB 是进程存在的唯一标识，因为它包含了进程的所有信息，并且用于操作系统对进程进行管理和控制。

## 📌 进程控制块 (PCB) 核心结构

<table>
    <tr>
    <td> PCB 组成部分 <br/></td><td> 作用描述 <br/></td><td> Linux 对应实现 <br/></td></tr>
    <tr>
    <td> 进程标识符 (PID) <br/></td><td>唯一标识进程的数字<br/></td><td>`task_struct->pid`<br/></td></tr>
    <tr>
    <td> 程序计数器 (PC) <br/></td><td>存储下一条要执行的指令地址<br/></td><td>`task_struct->thread.ip`<br/></td></tr>
    <tr>
    <td> 寄存器状态 <br/></td><td>保存 CPU 寄存器值（RAX/RSP等）<br/></td><td>`task_struct->thread.regs`<br/></td></tr>
    <tr>
    <td> 进程状态 <br/></td><td>标记运行态（TASK_RUNNING）、就绪态等<br/></td><td>`task_struct->state`<br/></td></tr>
    <tr>
    <td> 内存管理信息 <br/></td><td>页表指针、堆/栈边界<br/></td><td>`task_struct->mm`<br/></td></tr>
    <tr>
    <td> 文件描述符表 <br/></td><td>记录打开的文件（fd[0]~fd[n]）<br/></td><td>`task_struct->files`<br/></td></tr>
    <tr>
    <td> 调度信息 <br/></td><td>优先级（`prio`）、时间片剩余量<br/></td><td>`task_struct->sched_class`<br/></td></tr>
    <tr>
    <td> 父进程指针 <br/></td><td>指向创建该进程的父进程 PCB<br/></td><td>`task_struct->parent`<br/></td></tr>
    </table>



### **🌟**进程的生命周期

#### 进程创建

创建进程有三个主要事件：

- 系统初始化
- 用户请求创建一个新进程
- 一个正在运行的进程执行创建进程的系统调用

#### 进程运行

内核选择一个就绪的进程，让它占用处理机并运行，这里就涉及到了进程的调度策略，选择哪个进程调度？为什么选择调度这个进程呢？

#### 进程等待

在以下情况下进程会等待（阻塞）：

- 请求并等待系统服务，无法马上完成
- 启动某种操作，无法马上完成
- 需要的数据没有到达。

#### 进程唤醒

进程只能被别的进程或操作系统唤醒，唤醒进程的原因有：

- 被阻塞进程需要的资源可被满足
- 被阻塞进程等待的事件到达
- 将该进程的 PCB 插入到就绪队列

#### 进程结束

在以下四种情况下进程会结束：

- 自愿型正常退出
- 自愿型错误退出
- 强制型致命错误退出
- 强制型被其它进程杀死退出

### 进程的状态与转换

不同系统设置的进程状态是不同的，多数系统中的进程在生命结束前有三种基本状态，进程只会处于三种基本状态之一：

- **运行状态**：进程正在处理机上运行时就处在运行状态，该时刻进程时钟占用着 CPU；
- **就绪状态**：万事俱备，只欠东风，进程已经获得了除处理机之外的一切所需资源，一旦得到处理机就可以运行；就绪态中的进程其实可以运行，但因为其它进程正在占用着 CPU 而暂时停止运行；
- **等待状态（阻塞状态）**：进程正在等待某一事件而暂停运行，等待某个资源或者等待输入输出完成。除非某种外部事件发生，否则阻塞态的进程不能运行；

进程状态变化图如下：

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101740845.png)

在操作系统发现进程不能继续运行下去时，进程因为等待输入而被阻塞，进程从运行态转换到阻塞态！

调度程序选择了另一个进程执行时，当前程序就会从运行态转换到就绪态！

被调度程序选择的程序会从就绪态转换到运行态！

当阻塞态的进程等待的一个外部事件发生时，就会从阻塞态转换到就绪态，此时如果没有其他进程运行时，则立刻从就绪态转换到运行态！

有些与进程管理相关的系统调用有必要了解一下：

```cpp
pid=fork(); // 创建一个与父进程一样的子进程
pid=waitpid(); // 等待子进程终止
s=execve(); // 替换进程的核心映像
exit(); // 终止进程运行并返回状态值
s=sigaction(); // 定义信号处理的动作
s=sigprocmask(); // 检查或更换信号掩码
s=sigpending(); // 获得阻塞信号集合
s=sigsuspend(); // 替换信号掩码或挂起进程
alarm(); // 设置定时器
pause(); // 挂起调用程序直到下一个信号出现
```

## ⚙️ 进程状态转换对比

<table>
    <tr>
    <td> 状态转换 <br/></td><td> 触发条件 <br/></td><td> 相关系统调用/事件 <br/></td></tr>
    <tr>
    <td> 创建 → 就绪 <br/></td><td>`fork()` 成功创建子进程<br/></td><td>`clone()` / `do_fork()`<br/></td></tr>
    <tr>
    <td> 就绪 → 运行 <br/></td><td>被调度器选中（调用 `__schedule()`）<br/></td><td>`schedule()`<br/></td></tr>
    <tr>
    <td> 运行 → 阻塞 <br/></td><td>等待 I/O（如 `read()` 阻塞）或信号量<br/></td><td>`wait_event()` / `sleep()`<br/></td></tr>
    <tr>
    <td> 阻塞 → 就绪 <br/></td><td>I/O 完成（如磁盘中断触发）或信号量释放<br/></td><td>`wake_up_process()`<br/></td></tr>
    <tr>
    <td> 运行 → 终止 <br/></td><td>调用 `exit()` 或收到致命信号（`SIGKILL`）<br/></td><td>`do_exit()`<br/></td></tr>
    <tr>
    <td> 运行 → 就绪 <br/></td><td>时间片用完或被更高优先级进程抢占<br/></td><td>`timer_interrupt()`<br/></td></tr>
    </table>



### 什么是进程挂起？为什么会出现进程挂起？

进程挂起就是为了合理且充分的利用系统资源，把一个进程从内存转到外存。进程在挂起状态时，意味着进程没有占用内存空间，处在挂起状态的进程映射在磁盘上。进程挂起通常有两种状态：

- 阻塞挂起状态：进程在外存并等待某事件的出现；
- 就绪挂起状态：进程在外存，但只要进入内存即可运行。

有什么与进程挂起相关的状态转换？

进程挂起可能有以下几种情况：

- **阻塞到阻塞挂起**：没有进程处于就绪状态或就绪进程要求更多内存资源时，会进行这种转换，以提交新进程或运行就绪进程；
- **就绪到就绪挂起**：当有高优先级阻塞进程或低优先级就绪进程时，系统会选择挂起低优先级就绪进程；
- **运行到就绪挂起**：对于抢占式分时系统，当有高优先级阻塞挂起进程因事件出现而进入就绪挂起时，系统可能会把运行进程转到就绪挂起状态；
- **阻塞挂起到就绪挂起**：当有阻塞挂起进程有相关事件出现时，系统会把阻塞挂起进程转换为就绪挂起进程。

**有进程挂起那就有进程解挂：指一个进程从外存转到内存，相关状态有**：

- **就绪挂起到就绪**：没有就绪进程或就绪挂起进程优先级高于就绪进程时，就会进行这种转换；
- **阻塞挂起到阻塞**：当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起进程转换为阻塞进程。

## 🔄 中断处理流程（以 Linux 为例）

<table>
    <tr>
    <td> 步骤 <br/></td><td> 硬件/操作系统行为 <br/></td><td> 关键数据结构 <br/></td></tr>
    <tr>
    <td> 1. 硬件保存现场 <br/></td><td>压入 PC/PSW 到内核栈<br/></td><td>`pt_regs` 结构体<br/></td></tr>
    <tr>
    <td> 2. 加载中断向量 <br/></td><td>根据中断号跳转到 `entry_64.S` 中的中断入口<br/></td><td>IDT（中断描述符表）<br/></td></tr>
    <tr>
    <td> 3. 保存寄存器 <br/></td><td>汇编代码保存所有通用寄存器到 `pt_regs`<br/></td><td>`push %rax` 等指令<br/></td></tr>
    <tr>
    <td> 4. 切换堆栈 <br/></td><td>从用户栈切换到内核栈（`esp0`）<br/></td><td>`task_struct->thread.sp0`<br/></td></tr>
    <tr>
    <td> 5. 执行 ISR <br/></td><td>调用对应的中断处理函数（如键盘中断调用 `keyboard_interrupt()`）<br/></td><td>`irq_desc->action->handler`<br/></td></tr>
    <tr>
    <td> 6. 进程调度检查 <br/></td><td>判断是否需要调用 `schedule()` 切换进程<br/></td><td>`need_resched` 标志<br/></td></tr>
    <tr>
    <td> 7. 恢复寄存器 <br/></td><td>从 `pt_regs` 恢复寄存器状态<br/></td><td>`pop %rax` 等指令<br/></td></tr>
    <tr>
    <td> 8. 返回用户态 <br/></td><td>通过 `iretq` 指令恢复用户程序执行<br/></td><td>`swapgs` 指令（x86_64）<br/></td></tr>
    </table>



### **🌟**什么是线程？

线程是进程当中的一条执行流程，这几乎就是进程的定义，一个进程内可以有多个子执行流程，即线程。可以从两个方面重新理解进程：

- 从资源组合的角度：进程把一组相关的资源组合起来，构成一个资源平台环境，包括地址空间（代码段、数据段），打开的文件等各种资源
- 从运行的角度：代码在这个资源平台上的执行流程，然而线程貌似也是这样，但是进程比线程多了资源内容列表样式：那就有一个公式：进程 = 线程 + 共享资源

### 为什么使用线程？

因为要并发编程，在许多情形中同时发生着许多活动，而某些活动有时候会被阻塞，通过将这些活动分解成可以准并行运行的多个顺序流程是必须的，而如果使用多进程方式进行并发编程，进程间的通信也很复杂，并且**维护进程的系统开销较大**：创建进程时分配资源建立 PCB，撤销进程时回收资源撤销 PCB，进程切换时保存当前进程的状态信息。所以为了使并发编程的开销尽量小，所以引入多线程编程，可以并发执行也可以**共享相同的地址空间**。并行实体拥有共享同一地址空间和所有可用数据的能力，这是多进程模型所不具备的能力。

使用线程有如下优点：

- 可以多个线程存在于同一个进程中
- 各个线程之间可以并发的执行
- 各个线程之间可以共享地址空间和文件等资源
- 线程比进程更轻量级，创建线程撤销线程比创建撤销进程要快的多，在许多系统中，创建一个线程速度是创建一个进程速度的 10-100 倍。
- 如果多个线程是 CPU 密集型的，并不能很好的获得更好的性能，但如果多个线程是 IO 密集型的，线程存在着大量的计算和大量的 IO 处理，有多个线程允许这些活动彼此重叠进行，从而会加快整体程序的执行速度。

但也有缺点：

- 一旦一个线程崩溃，会导致其所属进程的所有线程崩溃。
- 由于各个线程共享相同的地址空间，那么读写数据可能会导致竞争关系，因此对同一块数据的读写需要采取某些同步机制来避免线程不安全问题。

### 什么时候用进程？什么时候用线程？

1. 进程是资源分配单位，线程是 CPU 调度单位；
2. 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
3. 线程同样具有就绪阻塞和执行三种基本状态，同样具有状态之间的转换关系；
4. 线程能减少并发执行的时间和空间开销：

   - 线程的创建时间比进程短
   - 线程的终止时间比进程短
   - 同一进程内的线程切换时间比进程短
   - 由于同一进程的各线程间共享内存和文件资源，可直接进行不通过内核的通信

**结论：**可以在强调性能时候使用线程，如果追求更好的容错性可以考虑使用多进程，google 浏览器据说就是用的多进程编程。在多 CPU 系统中，多线程是有益的，在这样的系统中，通常情况下可以做到真正的并行。

<table>
    <tr>
    <td> 指标 <br/></td><td>多进程模型<br/></td><td>多线程模型<br/></td></tr>
    <tr>
    <td> 创建速度 <br/></td><td>100ms<br/></td><td>1ms<br/></td></tr>
    <tr>
    <td> 内存占用 <br/></td><td>高（独立地址空间）<br/></td><td>低（共享地址空间）<br/></td></tr>
    <tr>
    <td> 通信延迟 <br/></td><td>高（需 IPC）<br/></td><td>低（共享内存）<br/></td></tr>
    <tr>
    <td> 崩溃影响范围 <br/></td><td>单个进程<br/></td><td>整个进程<br/></td></tr>
    </table>



### 进程和线程的比较

我们主要从调度，拥有资源 ，并发性，系统开销等方面对其进行比较：

- 调度：在传统的操作系统中，拥有资源和独立调度的单位都是进程，引入线程之后，调度的最小单位就变成了线程，但是拥有资源的最小单位还是进程，另外在同一个进程中，线程的切换不会影响进程，但是不同的进程中的切换则会引起进程切换。
- 拥有资源：不论是传统的操作系统，还是设有线程的操作系统，进程都是资源分配的最小单位。
- 并发性：在引入线程的操作系统中，不仅进程之间可以并发，线程之间也可以并发，这使得操作系统具有更好的并发性。
- 系统开销：创建进程或撤销进程的同时，系统都要为之分配或回收资源，在进行进程切换时，涉及当前进程 CPU 环境的保存和新环境的设置，线程切换时，只需保存和设置少量寄存器内容，因此开销很小。总的来说就是线程间切换的开销更小，同步和通信很容易实现。

### 线程是如何实现的？

线程的实现可分为用户线程和内核线程：

#### **用户线程**

在用户空间实现的线程机制，它不依赖于操作系统的内核，由一组用户级的线程库函数来完成线程的管理，包括进程的创建终止同步和调度等。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101740915.png)

用户线程有如下优点：

- 由于用户线程的维护由相应进程来完成（通过线程库函数），不需要操作系统内核了解内核了解用户线程的存在，可用于不支持线程技术的多进程操作系统。
- 每个进程都需要它自己私有的线程控制块列表，用来跟踪记录它的各个线程的状态信息（PC，栈指针，寄存器），TCB 由线程库函数来维护；
- 用户线程的切换也是由线程库函数来完成，无需用户态/核心态切换，所以速度特别快；
- 允许每个进程拥有自定义的线程调度算法；

但用户线程也有缺点：

- 阻塞性的系统调用如何实现？如果一个线程发起系统调用而阻塞，则整个进程在等待。
- 当一个线程开始运行后，除非它主动交出 CPU 的使用权，否则它所在进程当中的其它线程将无法运行；
- 由于时间片分配给进程，与其它进程比，在多线程执行时，每个线程得到的时间片较少，执行会较慢

#### 内核线程

是指在操作系统的内核中实现的一种线程机制，由操作系统的内核来完成线程的创建终止和管理。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101740827.png)

**特点**：

- 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息（PCB TCB）；
- 线程的创建终止和切换都是通过系统调用内核函数的方式来进行，由内核来完成，因此系统开销较大；
- 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其它内核线程的运行；
- 时间片分配给线程，多线程的进程获得更多 CPU 时间；

注意：

> 由于在内核中创建或撤销线程的代价比较大，某些系统采取复用的方式回收线程，当某个线程被撤销时，就把它标记不可运行，但是内核数据结构没有受到任何影响，如果后续又需要创建一个新线程时，就重新启动被标记为不可运行的旧线程，从而节省一些开销。

> 尽管使用内核线程可以解决很多问题，但还有些问题，例如：当一个多线程的进程创建一个新的进程时会发生什么？新进程是拥有与原进程相同数量的线程还是只有一个线程？在很多情况下，最好的选择取决于进程计划下一步做什么？如果它要调用 exec 启动一个新程序，或许一个线程正合适，但如果它继续运行，那么最好复制所有的线程。

#### 轻量级进程

它是内核支持的用户线程模型，一个进程可以有多个轻量级进程，每个轻量级进程由一个单独的内核线程来支持。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101739118.png)

在 Linux 下是没有真正的线程的，它所谓的线程其实就是使用进程来实现的，就是所谓的轻量级进程，其实就是进程，都是通过 clone 接口调用创建的，只不过两者传递的参数不同，通过参数决定子进程和父进程共享的资源种类和数量，进而有了普通进程和轻量级进程的区别。

# 🧵 线程实现方式对比

<table>
    <tr>
    <td> 对比维度 <br/></td><td> 用户线程 <br/></td><td> 内核线程 <br/></td><td> 轻量级进程 (LWP) <br/></td></tr>
    <tr>
    <td> 实现层级 <br/></td><td>用户空间（线程库实现）<br/></td><td>内核空间（操作系统直接支持）<br/></td><td>用户空间 + 内核支持（混合模型）<br/></td></tr>
    <tr>
    <td> 管理主体 <br/></td><td>用户级线程库（如 `pthread_create()`）<br/></td><td>操作系统内核（如 `clone()`）<br/></td><td>用户线程通过内核线程映射（1:1 或 M:N）<br/></td></tr>
    <tr>
    <td> TCB/PCB 存储 <br/></td><td>用户空间（线程库维护）<br/></td><td>内核空间（内核维护）<br/></td><td>内核维护 LWP 结构<br/></td></tr>
    <tr>
    <td> 创建/销毁开销 <br/></td><td>极低（无需内核介入）<br/></td><td>高（需系统调用）<br/></td><td>中（需内核参与但复用资源）<br/></td></tr>
    <tr>
    <td> 阻塞影响范围 <br/></td><td>整个进程阻塞（单线程阻塞则全部阻塞）<br/></td><td>仅阻塞当前线程<br/></td><td>仅阻塞当前 LWP<br/></td></tr>
    <tr>
    <td> 调度单位 <br/></td><td>进程（所有用户线程共享时间片）<br/></td><td>线程（内核直接调度线程）<br/></td><td>线程（内核调度 LWP）<br/></td></tr>
    <tr>
    <td> 并发性能 <br/></td><td>差（无法利用多核）<br/></td><td>好（真正并行）<br/></td><td>好（支持多核并行）<br/></td></tr>
    <tr>
    <td> 典型系统 <br/></td><td>早期 Java "绿色线程"<br/></td><td>Windows / Linux 原生线程<br/></td><td>Solaris / 现代 Java 虚拟线程<br/></td></tr>
    </table>



### **什么是僵尸进程**

僵尸进程是已完成且处于终止状态，但在进程表中却仍然存在的进程。僵尸进程通常发生在父子关系的进程中，由于父进程仍需要读取其子进程的退出状态所造成的。

### 进程切换

进程切换的速度是远小于线程切换的。举个不太恰当的例子，我们如果把进程比作房子，线程比作卧室的话，线程切换则是在每个卧室之间，来回穿梭，不用更换衣物，鞋子，但是我们如果要去邻居家（另一个进程）那么则需要更换衣服鞋子，这就是线程切换和进程切换。

**进程切换为什么慢？**

这就需要说到虚拟地址的地方了，因为每个进程都有自己的虚拟地址空间，然后线程共用当前进程的虚拟空间，所以进程切换需要虚拟地址空间的切换。这个过程是比较慢的。

另外进程通过查找页表，将虚拟空间映射到物理地址空间。这个过程是比较慢的，所以通常使用 Cache 来保存那些经常被查找的地址映射，然后进程切换的话，也会导致页表的切换，进而导致 Cache 失效，命中率降低，进而就会导致程序运行变慢。

### 协程

协程又叫微线程。

在有大量 IO 操作业务的情况下，考虑采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。

协程多用于异步 I/O，这样性能最好，阻塞 I/O 不能完全发挥出优势。

我们可以把协程理解成用户态的线程，操作系统不知道协程的存在，所以协程切换时不需要由操作系统控制，可以由自己控制，这样就节省了操作系统资源。

### **🌟**什么是上下文切换？

上下文切换指的是操作系统停止当前运行进程（从运行状态改变成其它状态）并且调度其它进程（就绪态转变成运行状态）。操作系统必须在切换之前存储许多部分的进程上下文，必须能够在之后恢复他们，所以进程不能显示它曾经被暂停过，同时切换上下文这个过程必须快速，因为上下文切换操作是非常频繁的。那**上下文指的是什么呢**？指的是任务所有共享资源的**工作现场**，每一个共享资源都有一个工作现场，包括用于处理函数调用、局部变量分配以及工作现场保护的栈顶指针，和用于指令执行等功能的各种寄存器。

注意：这里所说的进程切换导致上下文切换其实不太准确，准确的说应该是任务的切换导致上下文切换，这里的任务可以是进程也可以是线程，准确的说线程才是 CPU 调度的基本单位，但是因为各个资料都这么解释上下文切换，所以上面也暂时这么介绍，只要心里有这个概念就好。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101739124.png)

### 上下文切换的过程

1. 挂起一个进程，将这个进程在 CPU 中的状态（上下文信息）存储于内存的 PCB 中。
2. 在 PCB 中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复。
3. 跳转到[程序计数器](https://baike.baidu.com/item/%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/3219536)所指向的位置（即跳转到进程被中断时的代码行）并恢复该进程

## 📌 核心概念对比

<table>
    <tr>
    <td> 对比项 <br/></td><td> 进程上下文切换 <br/></td><td> 线程上下文切换 <br/></td></tr>
    <tr>
    <td> 切换对象 <br/></td><td>不同进程间的切换<br/></td><td>同一进程内不同线程间的切换<br/></td></tr>
    <tr>
    <td> 资源开销 <br/></td><td>高（需切换地址空间、刷新TLB、更新PCB）<br/></td><td>低（仅切换栈和寄存器，共享地址空间）<br/></td></tr>
    <tr>
    <td> 触发原因 <br/></td><td>时间片耗尽、系统调用阻塞、更高优先级进程抢占<br/></td><td>时间片耗尽、线程主动让出CPU（如`pthread_yield()`）<br/></td></tr>
    <tr>
    <td> 保存内容 <br/></td><td>寄存器状态、内存映射表、文件描述符表、信号处理等<br/></td><td>寄存器状态、栈指针（TCB）<br/></td></tr>
    <tr>
    <td> 速度 <br/></td><td>慢（约1000-5000 CPU周期）<br/></td><td>快（约100-1000 CPU周期）<br/></td></tr>
    <tr>
    <td> 硬件影响 <br/></td><td>导致CPU缓存和TLB大量失效<br/></td><td>仅部分缓存失效（共享内存数据可能保留）<br/></td></tr>
    </table>



## 💡 上下文切换的详细步骤

<table>
    <tr>
    <td> 步骤 <br/></td><td> 进程切换操作 <br/></td><td> 线程切换操作 <br/></td></tr>
    <tr>
    <td> 1. 保存现场 <br/></td><td>保存所有通用寄存器、浮点寄存器、程序计数器到PCB<br/></td><td>仅保存必要寄存器（PC/SP等）到TCB<br/></td></tr>
    <tr>
    <td> 2. 更新调度队列 <br/></td><td>将当前进程移入就绪/阻塞队列<br/></td><td>将当前线程移入线程就绪队列<br/></td></tr>
    <tr>
    <td> 3. 切换地址空间 <br/></td><td>加载新进程的页表指针（CR3寄存器），刷新TLB<br/></td><td>无此步骤（共享地址空间）<br/></td></tr>
    <tr>
    <td> 4. 恢复现场 <br/></td><td>从新进程的PCB恢复寄存器状态<br/></td><td>从新线程的TCB恢复寄存器<br/></td></tr>
    <tr>
    <td> 5. 切换堆栈 <br/></td><td>切换内核栈（`esp0`）和用户栈<br/></td><td>仅切换用户栈指针<br/></td></tr>
    </table>



### 为什么进程上下文切换比线程上下文切换代价高？

原文：[https://zwmst.com/1322.html](https://zwmst.com/1322.html)

**进程切换分两步：**

1. 切换页目录以使用新的地址空间
2. 切换内核栈和硬件上下文

对于 linux 来说，线程和进程的最大区别就在于地址空间，对于线程切换，第 1 步是不需要做 的，第 2 是进程和线程切换都要做的

**切换的性能消耗：**

线程上下文切换和进程上下文切换一个最主要的区别是线程的切换虚拟内存空间依然是相同 的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核 的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出

另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下 文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟 内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或 者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程 的切换中，不会出现这个问题。

# 🖥️ 进程 vs 线程上下文切换代价对比

<table>
    <tr>
    <td> 对比项 <br/></td><td> 进程上下文切换 <br/></td><td> 线程上下文切换 <br/></td><td> 关键差异说明 <br/></td></tr>
    <tr>
    <td> 地址空间切换 <br/></td><td>✅ 需要切换页目录（CR3寄存器）<br/></td><td>❌ 无需切换<br/></td><td>进程切换会导致TLB全部刷新，线程切换复用原地址空间<br/></td></tr>
    <tr>
    <td> TLB失效 <br/></td><td>✅ 全部失效<br/></td><td>❌ 保持有效<br/></td><td>TLB重建耗时约100-300周期（x86架构）<br/></td></tr>
    <tr>
    <td> CPU缓存失效 <br/></td><td>✅ L1/L2缓存大部分失效<br/></td><td>⚠️ 仅部分失效（共享数据保留）<br/></td><td>进程切换后缓存命中率下降明显<br/></td></tr>
    <tr>
    <td> 寄存器保存/恢复 <br/></td><td>✅ 保存全部寄存器+浮点寄存器<br/></td><td>✅ 仅保存必要寄存器<br/></td><td>线程切换需保存的数据量更少<br/></td></tr>
    <tr>
    <td> 内核栈切换 <br/></td><td>✅ 需切换内核栈和用户栈<br/></td><td>✅ 仅切换用户栈<br/></td><td>进程需要独立的内核栈空间<br/></td></tr>
    <tr>
    <td> 平均耗时 <br/></td><td>⏳ 1000-5000 CPU周期<br/></td><td>⏳ 100-1000 CPU周期<br/></td><td>实测线程切换速度可达进程的5-10倍<br/></td></tr>
    <tr>
    <td> 硬件优化支持 <br/></td><td>⚠️ PCID/ASID可部分优化TLB刷新<br/></td><td>✅ 天然优化（共享资源）<br/></td><td>Intel的PCID技术可降低进程切换开销<br/></td></tr>
    </table>



### 守护、僵尸、孤儿进程的概念

- 守护进程：运行在后台的一种特殊进程，独立于控制终端并周期性地执行某些任务。
- 僵尸进程：一个进程 fork 子进程，子进程退出，而父进程没有 wait/waitpid 子进程，那么子 进程的进程描述符仍保存在系统中，这样的进程称为僵尸进程。
- 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，这些子进程称为孤儿进程。 （孤儿进程将由 init 进程收养并对它们完成状态收集工作）

## **🌟**进程通信与线程通信

### 进程通信

进程通信，是指进程之间的信息交换（信息量少则一个状态或数值，多者则是成千上万个字 节）。因此，对于用信号量进行的进程间的互斥和同步，由于其所交换的信息量少而被归结为低级通信。

高级进程通信指：用户可以利用操作系统所提供的一组通信命令传送大量数据的一种通信 方式。操作系统隐藏了进程通信的实现细节。或者说，通信过程对用户是透明的

**高级通信机制可归结为三大类：**

**共享存储器系统（存储器中划分的共享存储区）；**实际操作中对应的是“剪贴板”（剪贴板实际 上是系统维护管理的一块内存区域）的通信方式，比如举例如下：word 进程按下 ctrl+c，在 ppt 进程按下 ctrl+v，即完成了 word 进程和 ppt 进程之间的通信，复制时将数据放入到剪贴 板，粘贴时从剪贴板中取出数据，然后显示在 ppt 窗口上

**消息传递系统**（进程间的数据交换以消息（message）为单位，当今最流行的微内核操作系统 中，微内核与服务器之间的通信，无一例外地都采用了消息传递机制。应用举例：邮槽（MailSlot）是基于广播通信体系设计出来的，它采用无连接的不可靠的数据传输。邮槽是一 种单向通信机制，创建邮槽的服务器进程读取数据，打开邮槽的客户机进程写入数据

**管道通信系统**（管道即：连接读写进程以实现他们之间通信的共享文件（pipe 文件，类似先进 先出的队列，由一个进程写，另一进程读））。实际操作中，管道分为：匿名管道、命名管道。匿名管道是一个未命名的、单向管道，通过父进程和一个子进程之间传输数据。匿名管道 只能实现本地机器上两个进程之间的通信，而不能实现跨网络的通信。命名管道不仅可以在本 机上实现两个进程间的通信，还可以跨网络实现两个进程间的通信。

- 管道：管道是单向的、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出 和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的道端读 出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。管道提供了简单的 流控制机制。进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已 经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。
- 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机 制，防止某进程正在访问共享资源时，其它进程也访问该资源。因此，主要作为进程间以及同 一进程内不同线程之间的同步手段
- 消息队列：是一个在系统内核中用来保存消 息的队列，它在系统内核中是以消息链表的形式出 现的。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺 点
- 共享内存：共享内存允许两个或多个进程访问同一个逻辑内存。这一段内存可以被两个或两个 以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共 享内存的进程，通过一个简单的内存读取读出，从而实现了进程间的通信。如果某个进程向共 享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。共享内 存是最快的 IPC 方式，它是针对其它进程间通信方式运行效率低而专门设计的。它往往与其它 通信机制（如信号量）配合使用，来实现进程间的同步和通信
- 套接字：套接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信。

由于各个进程不共享相同的地址空间，任何一个进程的全局变量在另一个进程中都不可见，所以如果想要在进程之间传递数据就需要通过内核，在内核中开辟出一块区域，该区域对多个进程都可见，即可用于进程间通信。有读者可能有疑问了，文件方式也是进程间通信啊，也要在内核开辟区域吗？这里说的内核区域其实是一段缓冲区，文件方式传输数据也有内核缓冲区的参与（零拷贝除外）。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101738360.png)

进程通信就是指进程间的信息交换，有多种进程间通信的方式：

- 管道
- 消息队列
- 共享内存
- 信号量
- 信号
- socket

# 🔄 进程通信 vs 线程通信机制对比

## 📌 通信方式分类

<table>
    <tr>
    <td> 通信类型 <br/></td><td> 进程通信 (IPC) <br/></td><td> 线程通信 <br/></td></tr>
    <tr>
    <td> 共享内存 <br/></td><td>✅ 需显式创建（如`shmget()`），配合信号量同步<br/></td><td>✅ 直接访问进程全局变量（需加锁）<br/></td></tr>
    <tr>
    <td> 消息传递 <br/></td><td>✅ 消息队列（`msgget`）、管道（`pipe`）、邮槽<br/></td><td>❌ 通常无需（可直接读写内存）<br/></td></tr>
    <tr>
    <td> 文件映射 <br/></td><td>✅ `mmap` 文件映射<br/></td><td>✅ 同进程通信<br/></td></tr>
    <tr>
    <td> 信号量 <br/></td><td>✅ `semget` 系统调用<br/></td><td>✅ 同进程通信（`pthread_mutex`）<br/></td></tr>
    <tr>
    <td> 信号 <br/></td><td>✅ `kill()` 发送信号<br/></td><td>⚠️ 有限支持（信号处理影响整个进程）<br/></td></tr>
    <tr>
    <td> 套接字 <br/></td><td>✅ 跨网络通信（`socket`）<br/></td><td>❌ 不适用<br/></td></tr>
    </table>



## 📊 进程通信方式详解

<table>
    <tr>
    <td> 机制 <br/></td><td> 原理 <br/></td><td> 特点 <br/></td><td> 典型API <br/></td></tr>
    <tr>
    <td> 匿名管道 <br/></td><td>单向字节流，内存中的固定大小队列<br/></td><td>仅限父子进程，单向通信<br/></td><td>`pipe()`<br/></td></tr>
    <tr>
    <td> 命名管道 <br/></td><td>文件系统中的特殊文件（FIFO）<br/></td><td>支持非亲缘进程，跨网络需SMB/NFS<br/></td><td>`mkfifo()`<br/></td></tr>
    <tr>
    <td> 消息队列 <br/></td><td>内核维护的消息链表<br/></td><td>支持消息类型标记，克服管道无结构限制<br/></td><td>`msgget()`/`msgsnd()`<br/></td></tr>
    <tr>
    <td> 共享内存 <br/></td><td>多个进程映射同一物理内存区域<br/></td><td>最快IPC方式，需配合同步机制<br/></td><td>`shmget()`/`shmat()`<br/></td></tr>
    <tr>
    <td> 信号量 <br/></td><td>内核计数器控制资源访问<br/></td><td>主要用于同步，不传递数据<br/></td><td>`sem_init()`/`sem_wait()`<br/></td></tr>
    <tr>
    <td> 套接字 <br/></td><td>网络协议栈接口<br/></td><td>跨主机通信，支持TCP/UDP<br/></td><td>`socket()`/`bind()`<br/></td></tr>
    </table>



## ⚙️ 线程同步机制

<table>
<tr>
<td>**机制**<br/></td><td>**作用**<br/></td><td>**特点**<br/></td><td>**POSIX API**<br/></td></tr>
<tr>
<td>**互斥锁**<br/></td><td>保护临界区<br/></td><td>简单高效，可能死锁<br/></td><td>`pthread_mutex_lock()`<br/></td></tr>
<tr>
<td>**条件变量**<br/></td><td>线程间状态通知<br/></td><td>需配合互斥锁使用<br/></td><td>`pthread_cond_wait()`<br/></td></tr>
<tr>
<td>**读写锁**<br/></td><td>区分读写操作<br/></td><td>读多写少场景性能优<br/></td><td>`pthread_rwlock_rdlock()`<br/></td></tr>
<tr>
<td>**自旋锁**<br/></td><td>忙等待锁<br/></td><td>短等待时比互斥锁高效<br/></td><td>`pthread_spin_lock()`<br/></td></tr>
<tr>
<td>**屏障**<br/></td><td>多线程同步点<br/></td><td>等待所有线程到达指定点<br/></td><td>`pthread_barrier_wait()`<br/></td></tr>
</table>


#### 管道

```cpp
ps auxf | grep mysql
```

中间的 `|` 就是管道，管道分为 `匿名管道` 和 `命名管道`。

##### 匿名管道

匿名管道就是 **pipe**，pipe 只能在父子进程间通信，而且数据只能**单向流动**（半双工通信）。

使用方式：

1. 父进程创建管道，会得到两个文件描述符，分别指向管道的两端；
2. 父进程创建子进程，从而子进程也有两个文件描述符指向同一管道；
3. 父进程可写数据到管道，子进程就可从管道中读出数据，从而实现进程间通信，下面的示例代码中通过 pipe 实现了每秒钟父进程向子进程都发送消息的功能。

```cpp
#include <stdio.h>
#include <string.h>
#include <unistd.h>
int main() {
    int _pipe[2];
    int ret = pipe(_pipe);
    if (ret < 0) {
        perror("pipe\n");
    }
    pid_t id = fork();
    if (id < 0) {
        perror("fork\n");
    } else if (id == 0) {  // 子进程
        close(_pipe[1]);
        int j = 0;
        char _mesg[100];
        while (j < 100) {
            memset(_mesg, '\0', sizeof(_mesg));
            read(_pipe[0], _mesg, sizeof(_mesg));
            printf("%s\n", _mesg);
            j++;
        }
    } else {  // 父进程
        close(_pipe[0]);
        int i = 0;
        char *mesg = NULL;
        while (i < 100) {
            mesg = "父进程来写消息了";
            write(_pipe[1], mesg, strlen(mesg) + 1);
            sleep(1);
            ++i;
        }
    }
    return 0;

}
```

我们平时也经常使用关于管道的命令行：

```cpp
ls | less
```

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101737119.png)

1. 创建管道
2. 为 ls 创建一个进程，设置 stdout 为管理写端
3. 为 less 创建一个进程，设置 stdin 为管道读端

##### 高级管道

通过 **popen** 将另一个程序当作一个新的进程在当前进程中启动，它算作当前进程的子进程，高级管道只能用在有亲缘关系的进程间通信，这种亲缘关系通常指父子进程，下面的 GetCmdResult 函数可以获取某个 Linux 命令执行的结果，实现方式就是通过 popen。

```cpp
std::string GetCmdResult(const std::string &cmd, int max_size = 10240) {
    char *data = (char *)malloc(max_size);
    if (data == NULL) {
        return std::string("malloc fail");
    }
    memset(data, 0, max_size);
    const int max_buffer = 256;
    char buffer[max_buffer];
    // 将标准错误重定向到标准输出
    FILE *fdp = popen((cmd + " 2>&1").c_str(), "r");
    int data_len = 0;

    if (fdp) {
        while (!feof(fdp)) {
            if (fgets(buffer, max_buffer, fdp)) {
                int len = strlen(buffer);
                if (data_len + len > max_size) {
                    cout << "data size larger than " << max_size;
                    break;
                }
                memcpy(data + data_len, buffer, len);
                data_len += len;
            }
        }
        pclose(fdp);
    }
    std::string ret(data, data_len);
    free(data);
    return ret;
}
```

##### 命名管道

有名字，可以双向传输，可以在非亲缘关系的进程间传输。

匿名管道有个缺点就是通信的进程一定要有亲缘关系，而命名管道就不需要这种限制。

命名管道其实就是一种特殊类型的文件，所谓的命名其实就是文件名，文件对各个进程都可见，通过命名管道创建好特殊文件后，就可以实现进程间通信。

可以通过 mkfifo 创建一个特殊的类型的文件，参数读者看名字应该就了解，一个是文件名，一个是文件的读写权限：

```cpp
int mkfifo(const char* filename, mode_t mode);
```

当返回值为 0 时，表示该命名管道创建成功，至于如何通信，其实就是个读写文件的问题！

管道的优点：方便，可以传输大量数据。

管道的缺点：效率相对于共享内存来说较低。

#### 消息队列

队列想必大家都知道，像 FIFO 一样，这里可以有多个进程写入数据，也可以有多个进程从队列里读出数据，但消息队列有一点比 FIFO 还更高级，它读消息不一定要使用先进先出的顺序，每个消息可以赋予类型，可以按消息的类型读取，不是指定类型的数据还存在队列中。本质上 MessageQueue 是存放在内核中的消息链表，每个消息队列链表会由消息队列标识符表示，这个消息队列存于内核中，只有主动的删除该消息队列或者内核重启时，消息队列才会被删除。

在 Linux 中消息队列相关的函数调用如下：

```cpp
// 创建和访问一个消息队列
int msgget(key_t, key, int msgflg);
// 用来把消息添加到消息队列中
int msgsend(int msgid, const void *msg_ptr, size_t msg_sz, int msgflg);
// msg_ptr是结构体数据的指针，结构第一个字段要有个类型：struct Msg {
    long int message_type;
    // 想要传输的数据
};
// 从消息队列中获取消息
int msgrcv(int msgid, void *msg_ptr, size_t msg_st, long int msgtype, int msgflg);
// 用来控制消息队列，不同的command参数有不同的控制方式
int msgctl(int msgid, int command, struct msgid_ds *buf);
```

示例代码如下：

```cpp
#include <errno.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/msg.h>

#include <chrono>
#include <iostream>
#include <thread>

using namespace std;

#define BUFFER_SIZ 20

typedef struct {
    long int msg_type;
    char text[BUFFER_SIZ];
} MsgWrapper;

void Receive() {
    MsgWrapper data;
    long int msgtype = 2;
    int msgid = msgget((key_t)1024, 0666 | IPC_CREAT);
    if (msgid == -1) {
        cout << "msgget error \n";
        return;
    }
    while (true) {
        if (msgrcv(msgid, (void *)&data, BUFFER_SIZ, msgtype, 0) == -1) {
            cout << "error " << errno << endl;
        }
        cout << "read data " << data.text << endl;
        if (strlen(data.text) > 6) {  // 发送超过6个字符的数据，结束
            break;
        }
    }
    if (msgctl(msgid, IPC_RMID, 0) == -1) {
        cout << "msgctl error \n";
    }
    cout << "Receive ok \n";
}

void Send() {
    MsgWrapper data;
    long int msgtype = 2;
    int msgid = msgget((key_t)1024, 0666 | IPC_CREAT);
    if (msgid == -1) {
        cout << "msgget error \n";
        return;
    }
    data.msg_type = msgtype;
    for (int i = 0; i < 10; ++i) {
        memset(data.text, 0, BUFFER_SIZ);
        char a = 'a' + i;
        memset(data.text, a, 1);
        if (msgsnd(msgid, (void *)&data, BUFFER_SIZ, 0) == -1) {
            cout << "msgsnd error \n";
            return;
        }
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
    memcpy(data.text, "1234567", 7);
    if (msgsnd(msgid, (void *)&data, BUFFER_SIZ, 0) == -1) {
        cout << "msgsnd error \n";
        return;
    }
}

int main() {
    std::thread r(Receive);
    r.detach();
    std::thread s(Send);
    s.detach();
    std::this_thread::sleep_for(std::chrono::seconds(20));
    return 0;
}

输出：root@iZuf64idor3ej648ciairaZ:~# ./a.out
read data a
read data b
read data c
read data d
read data e
read data f
read data g
read data h
read data i
read data j
read data 1234567
Receive ok
```

代码中为了演示方便使用消息队列进行的线程间通信，该代码同样用于进程间通信，消息队列的实现依赖于内核的支持，上述代码可能在某些系统（WSL）上不能运行，在正常的 Ubuntu 上可以正常运行。

#### 消息队列 vs 管道

**消息队列 > 命名管道**

1. 消息队列收发消息自动保证了同步，不需要由进程自己来提供同步方法，而命名管道需要自行处理同步问题；
2. 消息队列接收数据可以根据消息类型有选择的接收特定类型的数据，不需要像命名管道一样默认接收数据。

**消息队列 < 命名管道**

消息队列有一个缺点就是发送和接收的每个数据都有最大长度的限制。

#### 共享内存

如图：

<img src="https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101737852.png" style="zoom: 50%;" />

多个进程共同使用一块内存，自然可以通信。

可开辟中一块内存，用于各个进程间共享，使得各个进程可以直接读写同一块内存空间，就像线程共享同一块地址空间一样，该方式基本上是最快的进程间通信方式，因为没有系统调用干预，也没有数据的拷贝操作，但由于共享同一块地址空间，数据竞争的问题就会出现，需要自己引入同步机制解决数据竞争问题。

共享内存只是一种方式，它的实现方式有很多种，主要的有 mmap 系统调用、Posix 共享内存以及 System V 共享内存等。通过这三种“工具”共享地址空间后，通信的目的自然就会达到。

优点：效率高。

缺点：对开发者编程能力要求很高，很容易写出问题，特别是并发环境下。

#### **信号量**

信号量就是一个特殊的变量，程序对其访问都是原子操作，每个信号量开始都有个初始值。最简单最常见的信号量是只能取 0 和 1 的变量，也叫二值信号量。

信号量有两个操作，P 和 V：

- P：如果信号量变量值大于 0，则变量值减 1，如果值为 0，则阻塞进程；
- V：如果有进程阻塞在该信号量上，则唤醒阻塞的进程，如果没有进程阻塞，则变量值加 1

#### **信号**

信号也是进程间通信的一种方式，信号可以在任何时候发送给某一个进程，如果进程当前并未处于执行状态，内核将信号保存，直到进程恢复到执行态再发送给进程，进程可以对信号设置预处理方式，如果对信号设置了阻塞处理，则信号的传递会被延迟直到阻塞被取消，如果进程结束，那信号就被丢弃。我们常用的 CTRL+C 和 kill 等就是信号的一种，也达到了进程间通信的目的，进程也可以对信号设置 signal 捕获函数自定义处理逻辑。

这种方式有很大的缺点：只有通知的作用，通知了一下消息的类型，但不能传输要交换的任何数据。

Linux 系统中常见的信号有：

- SIGHUP：该信号在用户终端结束时发出，通常在中断的控制进程结束时，所有进程组都将收到该信号，该信号的默认操作是终止进程；
- SIGINT：程序终止信号，通常的 CTRL+C 产生该信号来通知终止进程；
- SIGQUIT：类似于程序错误信号，通常的 CTRL+\产生该信号通知进程退出时产生 core 文件；
- SIGILL：执行了非法指令，通常数据段或者堆栈溢出可能产生该信号；
- SIGTRAP：供调试器使用，由断电指令或其它陷阱指令产生；
- SIGABRT：使程序非正常结束，调用 abort 函数会产生该信号；
- SIGBUS：非法地址，通常是地址对齐问题导致，比如访问一个 4 字节长的整数，但其地址不是 4 的倍数；
- SIGSEGV：合理地址的非法访问，访问了未分配的内存或者没有权限的内存区域；
- SIGPIPE：管道破裂信号，socket 通信时经常会遇到，进程写入了一个无读者的管道；
- SIGALRM：时钟定时信号，由 alarm 函数设置的时间终止时产生；
- SIGFPE：出现浮点错误（比如除 0 操作）；
- SIGKILL：杀死进程（不能被捕捉和忽略）；

#### 文件

显而易见，多个进程可以操作同一个文件，所以也可以通过文件来进行进程间通信。

#### **socket**

很类似于网络通信，分为客户端和服务端：

<img src="https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101737999.png" style="zoom: 25%;" />

### 线程通信

所有线程共用所在进程的内存，所以肯定可以通信。但要注意线程安全问题，需要通过锁机制或者原子机制避免多线程环境下的数据竞争问题。

## **🌟**进程调度

当系统中有多个进程同时竞争 CPU，如果只有一个 CPU 可用，那同一时刻只会有一个进程处于运行状态，操作系统必须要选择下一个要运行的是哪个进程，在操作系统中，完成选择工作的这部分称为调度程序，该程序使用的算法称作**调度算法**。

### **什么时候进行调度？**

1. 系统调用创建一个新进程后，需要决定是运行父进程还是运行子进程
2. 一个进程退出时需要做出调度决策，需要决定下一个运行的是哪个进程
3. 当一个进程阻塞在 I/O 和信号量或者由于其它原因阻塞时，必须选择另一个进程运行
4. 当一个 I/O 中断发生时，如果中断来自 IO 设备，而该设备现在完成了工作，某些被阻塞的等待该 IO 的进程就成为可运行的就绪进程了，是否让新就绪的进程运行，或者让中断发生时运行的进程继续运行，或者让某个其它进程运行，这就取决于调度程序的抉择了。

### 调度的准则

- `CPU利用率`：如何调度可以使 CPU 的利用率达到最大
- `系统吞吐率`：系统吞吐量表示单位时间内 CPU 完成作业的数量
- `响应时间`：调度策略要尽量保证响应时间在用户接受的范围内
- `周转时间`：周转时间是作业从开始到完成所需的时间，尽量使这个时间较小。

### 调度的策略

不同系统环境下有不同的调度策略算法。调度算法也是有 KPI 的，对调度算法首先提的需求就是：

- **公平**：调度算法需要给每个进程公平的 CPU 份额，相似的进程应该得到相似的服务，对一个进程给予较其它等价的进程更多的 CPU 时间是不公平的，被普通水平的应届生工资倒挂也是不公平的！
- **执行力**：每一个策略必须强制执行，需要保证规定的策略一定要被执行。
- **平衡**：需要保证系统的所有部分尽可能都忙碌

### 进程调度算法 ⭐️⭐️⭐️

进程调度：多个进程都在等待处理器调度执行，处理器如何选择？

进程调度分为 `抢占式` 和 `非抢占式`。

**非抢占式调度算法**：挑选一个进程，然后让该进程运行直至被阻塞，或者直到该进程自动释放 CPU，即使该进程运行了若干个小时，它也不会被强迫挂起。这样做的结果是，在时钟中断发生时不会进行调度，在处理完时钟中断后，如果没有更高优先级的进程等待，则被中断的进程会继续执行。简单来说，调度程序必须等待事件结束。

非抢占方式引起进程调度的条件：

- 进程执行结束，或发生某个事件而不能继续执行
- 正在运行的进程因有 I/O 请求而暂停执行
- 进程通信或同步过程中执行了某些原语操作（wait、block 等）

**抢占式调度算法**：挑选一个进程，并且让该进程运行某个固定时段的最大值。如果在该时段结束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行，进行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便 CPU 控制返回给调度程序，如果没有可用的时钟，那么非抢占式调度就是唯一的选择。简单来说，就是当前运行的进程在事件没结束时就可以被换出，防止单一进程长时间独占 CPU 资源。下面会介绍很多抢占式调度算法：优先级算法、短作业优先算法、轮转算法等。

常见的进程调度算法：

因为不同的应用有不同的目标，不同的系统中，调度程序的优化也是不同的，大体可以分为三种环境：

#### 批处理系统

批处理系统的管理者为了掌握系统的工作状态，主要关注三个指标：

- 吞吐量：是系统每小时完成的作业数量
- 周转时间：指从一个作业提交到完成的平均时间
- CPU 利用率：尽可能让 CPU 忙碌，但又不能过量

具体调度算法：

- `先来先服务`：先来后到，就像平时去商店买东西需要排队一样，使用该算法，进程按照它们请求 CPU 的顺序来使用 CPU，该算法最大的优点就是简单易于实现，太容易的不一定是好的，该算法也有很大的缺点：平均等待时间波动较大，时间短的任务可能排队排在了时间长的任务后面。举个生活中的例子，排着队去取快递，如果每个人都很快取出来快递还好，如果前面有几个人磨磨唧唧到快递柜前才拿出手机打开 app，再找半分钟它的取件码，就会严重拖慢后面的人取快递的速度，同理排着队的进程如果每个进程都很快就运行完还好，如果其中有一个得到了 CPU 的进程运行时候磨磨唧唧很长时间都运行不完，那后面的进程基本上就没有机会运行了！
- `短作业优先调度`：该调度算法是非抢占式的算法，每个进程执行期间不会被打断，每次都选择执行时间最短的进程来调度，但问题来了，操作系统怎么可能知道进程具体的执行时间呢，所以该算法注定是基于预测性质的理想化算法，而且有违公平性，而且可能导致运行时间长的任务得不到调度。
- `最短剩余时间优先`：该调度算法是抢占式的算法，是最短作业优先的抢占版本，在进程运行期间，如果来了个更短时间的进程，那就转而去把 CPU 时间调度给这个更短时间的进程，它的缺点和最短作业优先算法类似。

#### 交互式系統

对于交互系统最重要的指标就是响应时间和均衡性：

- 响应时间：一个请求被提交到产生第一次响应所花费的时间。你给别人发微信别人看后不回复你或者几个小时后才回复你，你是什么感受，这还是交互式吗？
- 均衡性：减少平均响应时间的波动。需要符合固有期望和预期，你给别人发微信，他有时候秒回复，有时候几个小时后才回复。在交互式系统中，可预测性比高差异低平均更重要。

具体调度算法：

- 轮转调度：每个进程被分配一个时间段，称为时间片，即 CPU 做到雨露均沾，轮流翻各个进程的牌子，这段时间宠幸进程 A，下一段时间宠幸进程 B，再下一段时间宠幸进程 C，确保每个进程都可以获得 CPU 时间，如果 CPU 时间特别短的话，在外部看来像是同时宠幸了所有进程一样。那么问题来了，这个时间片究竟多长时间好呢？如果时间片设的太短会导致过多的进程切换，频繁的上下文切换会降低 CPU 效率，而如果时间片设的太长又可能对短的交互请求的响应时间变长，通常将时间片设为 20-50ms 是个比较合理的折中，大佬们的经验规则时维持上下文切换的开销处于 1% 以内。
- 优先级调度：上面的轮转调度算法是默认每个进程都同等重要，都有相同优先级，然而有时候进程需要设置优先级，例如某些播放视频的前台进程可以优先于某些收发邮件的后台守护进程被调度，在优先级调度算法中，每个优先级都有相应的队列，队列里面装着对应优先级的进程，首先在高优先级队列中进行轮转调度，当高优先级队列为空时，转而去低优先级队列中进行轮转调度，如果高优先级队列始终不为空，那么低优先级的进程很可能就会饥饿到很久不能被调度。
- 多级队列：多级队列算法与优先级调度算法不同，优先级算法中每个进程分配的是相同的时间片，而在多级队列算法中，不同队列中的进程分配给不同的时间片，当一个进程用完分配的时间片后就移动到下一个队列中，这样可以更好的避免上下文频繁切换。举例：有一个进程需要 100 个时间片，如果每次调度都给分配一个时间片，则需要 100 次上下文切换，这样 CPU 运行效率较低，通过多级队列算法，可以考虑最开始给这个进程分配 1 个时间片，然后被换出，下次分给它 2 个时间片，再换出，之后分给它 4、8、16、64 个时间片，这样分配的话，该进程只需要 7 次交换就可以运行完成，相比 100 次上下文切换运行效率高了不少，但顾此就会失彼，那些需要交互的进程得到响应的速度就会下降。
- 最短进程优先：交互式系统中应用最短进程优先算法其实是非常适合的，每次都选择执行时间最短的进程进行调度，这样可以使任务的响应时间最短，但这里有个任务，还没有运行呢，我怎么知道进程的运行时间呢？根本没办法非常准确的再当前可运行进程中找出最短的那个进程。有一种办法就是根据进程过去的行为进行预测，但这能证明是个好办法吗？
- 保证调度：这种调度算法就是向用户做出明确的可行的性能保证，然后去实现它。一种很实际的可实现的保证就是确保 N 个用户中每个用户都获得 CPU 处理能力的 1/N，类似的，保证 N 个进程中每个进程都获得 1/N 的 CPU 时间。
- 彩票调度：彩票调度算法基本思想是为进程提供各种资源（CPU 时间）的彩票，一旦需要做出调度决策时，就随机抽出一张彩票，拥有该彩票的进程获得该资源，很明显，拥有彩票越多的进程，获得资源的可能性越大。该算法在程序喵看来可以理解为股票算法，将 CPU 的使用权分成若干股，假设共 100 股分给了 3 个进程，给这些进程分别分配 20、30、50 股，那么它们大体上会按照股权比例（20：30：50）划分 CPU 的使用。
- 公平分享调度：假设有系统两个用户，用户 1 启动了 1 个进程，用户 2 启动了 9 个进程，如果使用轮转调度算法，那么用户 1 将获得 10% 的 CPU 时间，用户 2 将获得 90% 的 CPU 时间，这对用户来说公平吗？如果给每个用户分配 50% 的 CPU 时间，那么用户 2 中的进程获得的 CPU 时间明显比用户 1 中的进程短，这对进程来说公平吗？这就取决于怎么定义公平啦？

#### 实时系统

实时系统顾名思义，最关键的指标当然是实时：

- 满足截止时间：需要在规定 deadline 前完成作业；
- 可预测性：可预测性是指在系统运行的任何时刻，在任何情况下，实时系统的资源调配策略都能为争夺资源的任务合理的分配资源，使每个实时任务都能得到满足。

调度算法分类：

- 硬实时：必须在 deadline 之前完成工作，如果 delay，可能会发生灾难性或发生严重的后果；
- 软实时：必须在 deadline 之前完成工作，但如果偶尔 delay 了，也可以容忍。

具体调度算法：

- 单调速率调度：采用抢占式、静态优先级的策略，调度周期性任务。每个任务最开始都被配置好了优先级，当较低优先级的进程正在运行并且有较高优先级的进程可以运行时，较高优先级的进程将会抢占低优先级的进程。在进入系统时，每个周期性任务都会分配一个优先级，周期越短，优先级越高。这种策略的理由是：更频繁的需要 CPU 的任务应该被分配更高的优先级。
- 最早截止时间调度：根据截止时间动态分配优先级，截止时间越早的进程优先级越高。该算法中，当一个进程可以运行时，它应该向操作系统通知截止时间，根据截止时间的早晚，系统会为该进程调整优先级，以便满足可运行进程的截止时间要求。它与单调速率调度算法的区别就是一个是静态优先级，一个是动态优先级。

# ⏱️ 进程调度算法对比

## 📌 调度算法分类

<table>
    <tr>
    <td> 调度类型 <br/></td><td> 特点 <br/></td><td> 适用场景 <br/></td><td> 优缺点 <br/></td></tr>
    <tr>
    <td> 非抢占式 <br/></td><td>进程持续运行直到阻塞或结束<br/></td><td>批处理系统<br/></td><td>✅ 简单高效<br/>❌ 长任务可能阻塞短任务<br/></td></tr>
    <tr>
    <td> 抢占式 <br/></td><td>通过时间片强制切换进程<br/></td><td>交互式/实时系统<br/><br/></td><td>✅ 公平性高<br/>❌ 上下文切换开销大<br/></td></tr>
    </table>



## 🔄 常见调度算法对比

<table>
    <tr>
    <td> 算法名称 <br/></td><td> 调度策略 <br/></td><td> 系统类型 <br/></td><td> 关键特点 <br/></td></tr>
    <tr>
    <td> 先来先服务 (FCFS) <br/></td><td>按请求顺序执行<br/></td><td>批处理<br/></td><td>❌ 平均等待时间波动大<br/>✅ 实现简单<br/></td></tr>
    <tr>
    <td> 短作业优先 (SJF) <br/></td><td>选择预估执行时间最短的进程<br/></td><td>批处理<br/></td><td>✅ 最小化平均等待时间<br/>❌ 可能导致长任务饥饿<br/></td></tr>
    <tr>
    <td> 轮转调度 (RR) <br/></td><td>固定时间片轮流执行<br/></td><td>交互式<br/></td><td>⚖️ 时间片设置敏感（推荐20-50ms）<br/>✅ 公平性高<br/></td></tr>
    <tr>
    <td> 优先级调度 <br/></td><td>按优先级分配CPU，同优先级轮转<br/></td><td>交互式/实时<br/></td><td>❌ 低优先级可能饥饿<br/>✅ 支持关键任务优先<br/></td></tr>
    <tr>
    <td> 多级队列 <br/></td><td>不同队列分配不同时间片，进程随时间片用完降级<br/></td><td>交互式<br/></td><td>✅ 减少短作业切换开销<br/>❌ 长作业响应延迟<br/></td></tr>
    <tr>
    <td> 单调速率 (RM) <br/></td><td>周期越短优先级越高（静态）<br/></td><td>实时系统<br/></td><td>✅ 可预测性强<br/>❌ 需已知任务周期<br/></td></tr>
    <tr>
    <td> 最早截止时间 (EDF) <br/></td><td>截止时间越早优先级越高（动态）<br/></td><td>实时系统<br/></td><td>✅ 动态适应性强<br/>❌ 计算复杂度较高<br/></td></tr>
    </table>



## 📊 性能指标对比

<table>
    <tr>
    <td> 指标 <br/></td><td> 批处理系统关注 <br/></td><td> 交互式系统关注 <br/></td><td> 实时系统关注 <br/></td></tr>
    <tr>
    <td> 核心目标 <br/></td><td>吞吐量、周转时间<br/></td><td>响应时间、均衡性<br/></td><td>截止时间、可预测性<br/></td></tr>
    <tr>
    <td> 优化方向 <br/></td><td>CPU利用率最大化<br/></td><td>用户交互体验<br/></td><td>任务时限保证<br/></td></tr>
    <tr>
    <td> 典型算法 <br/></td><td>FCFS/SJF<br/></td><td>RR/优先级<br/></td><td>RM/EDF<br/></td></tr>
    </table>



#### 如何配置调度策略

调度算法有很多种，各有优缺点，操作系统自己很少能做出最优的选择，那么可以把选择权交给用户，由用户根据实际情况来选择适合的调度算法，这就叫策略与机制分离，调度机制位于内核，调度策略由用户进程决定，将调度算法以某种形式参数化，由用户进程来选择参数从而决定内核使用哪种调度算法。

### 操作系统如何完成的进程调度？

进程的每次变化都会有相应的状态，而操作系统维护了一组状态队列，表示系统中所有进程的当前状态；不同的状态有不同的队列，有就绪队列阻塞队列等，每个进程的 PCB 都根据它的状态加入到相应的队列中，当一个进程的状态发生变化时，它的 PCB 会从一个状态队列中脱离出来加入到另一个状态队列。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101735635.png)

注意图中同一种状态为什么有多个队列呢？因为进程有优先级概念，相同状态的不同队列的优先级不同。

## **🌟**同步与互斥

### 进程同步的方法

操作系统中，进程是具有不同的地址空间的，两个进程是不能感知到对方的存在的。有时候，需要多个进程来协同完成一些任务。

当多个进程需要对同一个内核资源进行操作时，这些进程便是竞争的关系，操作系统必须协调各个进程对资源的占用，进程的互斥是解决进程间竞争关系的方法。 进程互斥指若干个进程要使用同一共享资源时，任何时刻最多允许一个进程去使用，其他要使用该资源的进程必须等待，直到占有资源的进程释放该资源。

当多个进程协同完成一些任务时，不同进程的执行进度不一致，这便产生了进程的同步问题。需要操作系统干预，在特定的同步点对所有进程进行同步，这种协作进程之间相互等待对方消息或信号的协调关系称为进程同步。进程互斥本质上也是一种进程同步。

进程的同步方法：

1. 互斥锁
2. 读写锁
3. 条件变量
4. 记录锁(record locking)
5. 信号量
6. 屏障（barrier）

<table>
<tr>
<td>序号<br/></td><td>同步方法<br/></td><td>描述<br/></td></tr>
<tr>
<td>1<br/></td><td>互斥锁<br/></td><td>确保任意时刻最多只有一个进程访问共享资源，用于实现对共享资源的互斥访问。<br/></td></tr>
<tr>
<td>2<br/></td><td>读写锁<br/></td><td>多个读操作可以同时进行，但在写操作时不允许其他读或写操作，适用于读多写少的场景。<br/></td></tr>
<tr>
<td>3<br/></td><td>条件变量<br/></td><td>允许线程在某个条件满足之前阻塞自己，常与互斥锁结合使用来协调不同线程间的执行顺序。<br/></td></tr>
<tr>
<td>4<br/></td><td>记录锁(record locking)<br/></td><td>进程可以锁定文件的部分或全部内容，以避免与其他进程对该部分内容的并发访问冲突。<br/></td></tr>
<tr>
<td>5<br/></td><td>信号量<br/></td><td>可以用来控制对共享资源的访问，通过计数器机制允许一定数量的线程同时访问资源。<br/></td></tr>
<tr>
<td>6<br/></td><td>屏障（barrier）<br/></td><td>设定一个同步点，所有参与的进程/线程必须到达该点后才能继续执行，确保所有进程同步进行。<br/></td></tr>
</table>


### 线程同步的方法

操作系统中，属于同一进程的线程之间具有相同的地址空间，线程之间共享数据变得简单高效。遇到竞争的线程同时修改同一数据或是协作的线程设置同步点的问题时，需要使用一些线程同步的方法来解决这些问题。

线程同步的方法：

1. 互斥锁
2. 读写锁
3. 条件变量
4. 信号量
5. 自旋锁
6. 屏障（barrier）

<table>
<tr>
<td>序号<br/></td><td>同步方法<br/></td><td>描述<br/></td></tr>
<tr>
<td>1<br/></td><td>互斥锁<br/></td><td>确保任意时刻最多只有一个线程访问共享资源，用于实现对共享资源的互斥访问。<br/></td></tr>
<tr>
<td>2<br/></td><td>读写锁<br/></td><td>多个读操作可以同时进行，但在写操作时不允许其他读或写操作，适用于读多写少的场景。<br/></td></tr>
<tr>
<td>3<br/></td><td>条件变量<br/></td><td>允许线程在某个条件满足之前阻塞自己，常与互斥锁结合使用来协调不同线程间的执行顺序。<br/></td></tr>
<tr>
<td>4<br/></td><td>信号量<br/></td><td>可以用来控制对共享资源的访问，通过计数器机制允许一定数量的线程同时访问资源。<br/></td></tr>
<tr>
<td>5<br/></td><td>自旋锁<br/></td><td>线程在等待获取锁的时候不会进入睡眠状态，而是循环等待，适合于锁被持有的时间非常短的情况。<br/></td></tr>
<tr>
<td>6<br/></td><td>屏障（barrier）<br/></td><td>设定一个同步点，所有参与的线程必须到达该点后才能继续执行，确保所有线程同步进行。<br/></td></tr>
</table>


### 进程同步与线程同步有什么区别

进程之间地址空间不同，不能感知对方的存在，同步时需要将锁放在多进程共享的空间。而线程之间共享同一地址空间，同步时把锁放在所属的同一进程空间即可。

### 临界区和临界资源

`临界资源`：同时只能允许一个进程访问的资源。

`临界区`：进程中用于访问临界资源的代码。

### 如何防止多个进程同时进入临界区？

- 闲时让进：空闲状态你可以进入
- 忙则等待：有人正在用，你等一等
- 有限等待：不会让你一直等的放心好啦
- 让权等待：你出问题了，就别占着位置啦，让别人用吧。

### 同步和互斥的经典示例

生产者-消费者问题

> 一组生产者向一组消费者提供产品，他们共享一个缓冲区，生产者会向里面投放物品，消费者从里面取走产品。
> 但是这个里面存在一些问题：
>
> - 缓冲区内没有物品，消费者还不断取
> - 缓冲区已经满了，生产者还在不断放入
> - 多个消费者同时取

### 读写锁

多线程环境下对共享资源的读多写少场景，使用读写锁正适合，它通过区分读操作和写操作，可以显著提高并发性能。

- 读锁：多个线程可同时持有读锁（共享访问）。
- 写锁：仅一个线程能持有写锁，且期间不允许任何读锁或其他写锁（独占访问）。

优势：

- 读操作不互斥，适合读多写少的场景（如缓存、数据库）。
- 写操作独占资源，避免数据竞争。

### 读饥饿是什么

读饥饿是读写锁中的一种现象，指写线程因读线程持续占用锁而长时间无法获取写锁，导致写操作被“饿死”（无法执行）。这种现象在高并发读场景下很常见。

原因：

- 多个读线程频繁获取读锁（共享访问）。
- 写线程尝试获取写锁时，必须等待所有读锁释放。
- 若读锁的获取是连续的（无间隙），写线程将无限等待。

危害：

- 数据更新延迟：写操作无法执行，导致数据长时间不更新。
- 系统响应下降：写线程阻塞可能引发超时或死锁。
- 公平性破坏：违背“先来先服务”原则。

解决方案：

- 公平读写锁：通过队列或优先级机制，保证写锁请求不会被后续读锁插队。比如一旦有写锁请求，后续读锁必须等待写锁完成。
- 限制读锁持有时间：设置读锁的最大持有时间，超时后自动释放。
- 避免长期持有读锁：将长耗时读操作拆分为多个短操作，间歇释放锁。

## **🌟**死锁

### 死锁产生的条件

- `请求和保持`：请求新资源的同时，保持住已的占有资源不松手
- `互斥`：某一时刻下，一个资源只能一个进程所占有
- `不可剥夺`：获得的资源没有使用完时，别人不可以抢走
- `循环等待`：没有获得新资源，绝不死心。

### 处理死锁的方法

- `鸵鸟法`：对死锁不管不问
- `预防死锁`：设置某些限制条件，破坏死锁产生的四个条件之一
- `避免死锁`：资源分配的动态过程中，用某种方法防止系统进入不安全状态，从而避免死锁的发生。
- `检测死锁`：专门喊个人来检测死锁是否存在。

### 死锁预防

破坏四个条件之一：

- `互斥条件`：不太可能通过这个来解决
- `请求和保持`：静态分配，进程运行之前先分配所有资源给他
- `不可剥夺`：当某个资源长时间不能获得需要的新资源时，则放弃他的所有资源
- `循环等待`：当等待一段时间还没有获得资源时，则放弃等待

### 死锁的检测和解除

`死锁检测`：可以通过资源分配图来检测进程的资源占用情况及申请情况，进而来判断是否产生了死锁。如果资源分配图构成了环，则表示有死锁。

`死锁解除`：可以通过 `剥夺资源`、`进程撤销` 等方式来解除死锁。

### 死锁产生的条件

<table>
<tr>
<td>序号<br/></td><td>条件名称<br/></td><td>描述说明<br/></td></tr>
<tr>
<td>1<br/></td><td>请求和保持<br/></td><td>进程在请求新资源的同时，不释放已占有的资源<br/></td></tr>
<tr>
<td>2<br/></td><td>互斥<br/></td><td>资源不能共享，某一时刻只能被一个进程占用<br/></td></tr>
<tr>
<td>3<br/></td><td>不可剥夺<br/></td><td>资源只能由占有它的进程主动释放，不能被强制剥夺<br/></td></tr>
<tr>
<td>4<br/></td><td>循环等待<br/></td><td>存在一个进程链，每个进程都在等待下一个进程所持有的资源<br/></td></tr>
</table>


## 处理死锁的方法

<table>
<tr>
<td>方法名称<br/></td><td>描述说明<br/></td></tr>
<tr>
<td>鸵鸟法<br/></td><td>忽略死锁问题，认为其发生概率极低，系统不做任何处理<br/></td></tr>
<tr>
<td>预防死锁<br/></td><td>破坏死锁产生的四个必要条件之一，防止死锁发生<br/></td></tr>
<tr>
<td>避免死锁<br/></td><td>在资源动态分配过程中，通过算法确保系统始终处于安全状态，避免进入死锁状态<br/></td></tr>
<tr>
<td>检测死锁<br/></td><td>定期运行检测算法，检查系统中是否存在死锁，若存在则采取措施解除<br/></td></tr>
</table>


# 内存管理篇

## **🌟**什么是物理内存？

我们常说的物理内存大小就是指内存条的大小，一般买电脑时都会看下内存条是多大容量。

话说如果内存条大小是 100G，那这 100G 就都能够被使用吗？不一定，更多的还是要看 CPU 地址总线的位数，如果地址总线只有 20 位，那么它的寻址空间就是 1MB，即使可以安装 100G 的内存条也没有意义，也只能视物理内存大小为 1MB。

## 物理内存的缺点

这种方式下每个程序都可以直接访问物理内存，有两种情况：

1. 系统中只有一个进程在运行：如果用户程序可以操作物理地址空间的任意地址，它们就很容易在不经意间破坏了操作系统，使系统出现各种奇奇怪怪的问题。
2. 系统有多个进程同时在运行：如图，理想情况下可以使进程 A 和进程 B 各占物理内存的一边，两者互不干扰，但这也只是在理想情况下。

   1. 进程 B 在后台正常运行着，程序员在调试进程 A 时有可能就会误操作到进程 B 正在使用的物理内存，导致进程 B 运行出现异常，两个程序操作了同一地址空间，第一个程序在某一地址空间写入某个值，第二个程序在同一地址又写入了不同值，这就会导致程序运行出现问题，所以直接使用物理内存会使所有进程的**安全性得不到保证**。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101735255.png)

**如何解决？**

可以考虑为存储器创造新的抽象概念：`地址空间`。

地址空间为程序创造了一种抽象的内存，是进程可用于寻址内存的一套地址集合，同时每个进程都有一套自己的地址空间，一个进程的地址空间独立于其它进程的地址空间。

**如何为程序创造独立的地址空间？**

最简单的办法就是把每个进程的地址空间分别映射到物理内存的不同部分。这样就可以保证不同进程使用的是独立的地址空间。

> 给每个进程提供一个基址 A 和界限 B，进程内使用的空间为 x，则对应的物理地址为 A + x，同时需要保证 A + x < B，如果访问的地址超过的界限，需要产生错误并中止访问。
> 为了达到目的，CPU 配置了两个特殊硬件寄存器：基址寄存器和界限寄存器，当一个进程运行时，程序的起始物理地址和长度会分别装入到基址寄存器和界限寄存器里，进程访问内存，在每个内存地址送到内存之前，都会先加上基址寄存器的内容。

**缺点：**每次访问内存都需要进行加法和比较运算，比较运算很快，但是加法运算由于进位传递事件的问题，在没有使用特殊电路的情况下会显得很慢。

此外，每个进程运行都会占据一定的物理内存，如果物理内存足够大到可以容纳许多个进程同时运行还好，但现实中物理内存的大小是有限的，可能会出现**内存不够用**的情况，怎么办？

方法 1：如果是因为程序太大，大到超过了内存的容量，可以采用 `手动覆盖` 技术，只把需要的指令和数据保存在内存中。

方法 2：如果是因为程序太多，导致超过了内存的容量，可以采用 `自动交换` 技术，把暂时不需要执行的程序移动到外存中。

### 覆盖技术

把程序按照自身逻辑结构，划分成多个功能相互独立的程序模块，那些不会同时执行的模块可以共享到同一块内存区域，按时间顺序来运行：

- 将常用功能需要的代码和数据常驻在内存中；
- 将不常用的功能划分成功能相互独立的程序模块，平时放到外存中，在需要的时候将对应的模块加载到内存中；
- 那些没有调用关系的模块平时不需要装入到内存，它们可以共用一块内存区，需要时加载到内存，不需要时换出到外存中；

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101735018.png)

### 交换技术

多个程序同时运行，可以将暂时不能运行的程序送到外存，获得更多的空闲内存，操作系统将一个进程的整个地址空间内容**换出**到外存中，再将外存中某个进程的整个地址空间信息**换入**到内存中，换入换出内容的大小是整个程序的地址空间。

交换技术在实现上有很多困难：

- 需要确定什么时候发生交换：简单的办法是可以在内存空间不够用时换出一些程序；
- 交换区必须足够大：多个程序运行时，交换区（外存）必须足够大，大到可以存放所有程序所需要的地址空间信息；
- 程序如何换入：一个程序被换出后又重新换入，换入的内存位置可能不会和上一次程序所在的内存位置相同，这就需要动态地址映射机制。

### 覆盖 vs 交换

- 覆盖只能发生在那些相互之间没有调用关系的程序模块之间，因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构。
- 交换技术是以在内存中的程序大小为单位来进行的，它不需要程序员给出各个模块之间的逻辑覆盖结构。

通俗来说：覆盖发生在程序的内部，交换发生在程序与程序之间。

但是这两种技术都有**缺点**：

- 覆盖技术：需要程序员自己把整个程序划分为若干个小的功能模块，并确定各个模块之间的覆盖关系，增加了程序员的负担，很少有程序员擅长这种技术；
- 交换技术：以进程作为交换的单位，需要把进程的整个地址空间都换进换出，增加了处理器的开销，还需要足够大的外存。

那有没有更好的解决上述问题的方法呢？答案是**虚拟内存技术**。

<table>
    <tr>
    <td>对比维度<br/></td><td>覆盖技术<br/></td><td>交换技术<br/></td></tr>
    <tr>
    <td> 发生范围 <br/></td><td>程序内部模块之间<br/></td><td>不同程序（进程）之间<br/></td></tr>
    <tr>
    <td> 管理单位 <br/></td><td>程序模块（函数/代码段）<br/></td><td>整个进程的地址空间<br/></td></tr>
    <tr>
    <td> 实现方式 <br/></td><td>程序员手动划分模块和覆盖关系<br/></td><td>操作系统自动管理<br/></td></tr>
    <tr>
    <td> 外存需求 <br/></td><td>仅需存放不常用模块<br/></td><td>需存放整个进程的地址空间（交换区需足够大）<br/></td></tr>
    <tr>
    <td> 地址映射 <br/></td><td>模块加载位置固定（需程序员指定）<br/></td><td>动态地址映射（换入位置可能变化）<br/></td></tr>
    <tr>
    <td> 优点 <br/></td><td>1. 减少常驻内存代码<br/>2. 适合早期内存极小场景<br/></td><td>1. 程序员无需干预<br/>2. 支持多程序并发<br/></td></tr>
    <tr>
    <td> 缺点 <br/></td><td>1. 增加编程复杂度<br/>2. 模块间不能有调用关系<br/>3. 难以维护<br/></td><td>1. 换入换出开销大<br/>2. 外存占用多<br/>3. 可能引发抖动（频繁交换）<br/></td></tr>
    <tr>
    <td> 适用场景 <br/></td><td>内存极端受限的单道程序系统（如DOS时代游戏）<br/></td><td>早期多道程序系统（如Unix早期版本）<br/></td></tr>
    <tr>
    <td> 是否需要OS支持 <br/></td><td>基本不需要（由程序逻辑实现）<br/></td><td>需要操作系统提供交换管理机制<br/></td></tr>
    </table>



## **🌟**什么是虚拟内存？

**虚拟内存**，那就是虚拟出来的内存，它的基本思想就是确保每个程序拥有自己的地址空间，地址空间被分成多个块，每一块都有连续的地址空间，同时物理空间也分成多个块，块大小和虚拟地址空间的块大小一致，操作系统会自动将虚拟地址空间映射到物理地址空间，程序所关注的只是虚拟内存，请求的也是虚拟内存，其实真正使用的是物理内存。

虚拟内存技术有覆盖技术的功能，但它不是把程序的所有内容都放在内存中，因而能够运行比当前的空闲内存空间还要大的程序。它比覆盖技术做的更好，整个过程由操作系统自动来完成，无需程序员的干涉；

虚拟内存技术有交换技术的功能，能够实现进程在内存和外存之间的交换，因而获得更多的空闲内存空间。它比交换技术做的更好，它只对进程的部分内容在内存和外存之间进行交换。

**虚拟内存技术的具体实现：**

虚拟内存技术一般是在页式管理（下面介绍）的基础上实现：

- 在装入程序时，不必将其全部装入到内存，而只需将当前需要执行的部分页面装入到内存，就可让程序开始执行；
- 在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页）。则由处理器通知操作系统将相应的页面调入到内存，然后继续执行程序；
- 另一方面，操作系统将内存中暂时不使用的页面调出保存在外存上，从而腾出更多空闲空间存放将要装入的程序以及将要调入的页面。

**虚拟内存技术的特点：**

- 大的用户空间：通过把物理内存与外存相结合，提供给用户的虚拟内存空间通常大于实际的物理内存，即实现了两者的分离。如 32 位的虚拟地址理论上可以访问 4GB，而可能计算机上仅有 256M 的物理内存，但硬盘容量大于 4GB；
- 部分交换：与交换技术相比较，虚拟存储的调入和调出是对部分虚拟地址空间进行的；
- 连续性：程序可以使用一系列相邻连续的虚拟地址来映射物理内存中不连续的大内存缓冲区；
- 安全性：不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

## **为什么要有虚拟地址空间呢？**

1. 先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，程序都是直接访问和操作的都是物理内存 。但是这样有什么问题呢？
2. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。

想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

## 虚拟内存如何映射到物理内存？

如图，CPU 里有一个内存管理单元（Memory Management Unit），简称 MMU，虚拟内存不是直接送到内存总线，而是先给到 MMU，由 MMU 来把虚拟地址映射到物理地址，程序只需要管理虚拟内存就好，映射的逻辑自然有其它模块自动处理。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101735628.png)

## 什么是分页内存管理？

将虚拟地址空间分成若干个块，每个块都有固定的大小，物理地址空间也被划分成若干个块，每个块也都有固定的大小，物理地址空间的块和虚拟地址空间的块大小相等，虚拟地址空间这些块就被称为**页面**，物理地址空间这些块被称为**帧**。

关于分页这里有个问题，页面的大小是多少合适呢？页面太大容易产生空间浪费，程序假如只使用了 1 个字节却被分配了 10M 的页面，这岂不是极大的浪费，页面太小会导致页表（下面介绍）占用空间过大，所以页面需要折中选择合适的大小，目前大多数系统都使用 4KB 作为页的大小。

上面关于虚拟内存如何映射到物理内存，只介绍了 MMU，但是 MMU 是如何工作的还没有介绍，MMU 通过**页表**这个工具将虚拟地址转换为物理地址。32 位的虚拟地址分成两部分（虚拟页号和偏移量），MMU 通过页表找到了虚拟页号对应的物理页号，物理页号 + 偏移量就是实际的物理地址。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101735462.png)

上图只表示了页表的大体功能，页表的结构其实还很复杂，继续往下看。

页表的目的就是虚拟页面映射为物理内存的页框，页表可以理解为一个数学函数，函数的输入是虚拟页号，函数的输出是物理页号，通过这个函数可以把虚拟页面映射到物理页号，从而确定物理地址。不同机器的页表结构不同，通常页表的结构如下：

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101735398.png)

- **页框号：**最主要的一项，页表最主要的目的就是找到物理页号；
- **有效位：**1 表示有效，表示该表项是有效的，如果为 0，表示该表项对应的虚拟页面现在不在内存中，访问该页面会引起缺页中断，缺页中断后会去物理空间找到一个可用的页框填回到页表中；
- **保护位：**表示一个页允许什么类型的访问，可读可写还是可执行；
- **修改位：**该位反应了页面的状态，在操作系统重新分配页框时有用，在写入一页时由硬件自动设置该位，重新分配页框时，如果一个页面已经被修改过，则必须把它这个脏页写回磁盘，如果没有被修改过，表示该页是干净的，它在磁盘上的副本依然是有效的，直接丢弃该页面即可。
- **访问位：**该位主要用于帮助操作系统在发生缺页中断时选择要被淘汰的页面，不再使用的页面显然比正在使用的页面更适合被淘汰，该位在页面置换算法中发挥重要作用。
- **高速缓存禁止位：**该位用于禁止该页面被高速缓存。

### 如何加快地址映射速度？

每次访问内存都需要进行虚拟地址到物理地址的映射，每次映射都需要访问一次页表，所有的指令执行都必须通过内存，很多指令也需要访问内存中的操作数，因此每条指令执行基本都会进行多次页表查询，为了程序运行速度，指令必须要在很短的时间内执行完成，而页表查询映射不能成为指令执行的瓶颈，所以需要提高页表查询映射的速度。

**如何才能提高速度呢？**可以为页表提供一个缓存，通过缓存进行映射比通过页表映射速度更快，这个缓存是一个小型的硬件设备，叫 `快表（TLB）`，MMU 每次进行虚拟地址转换时，首先去 TLB 中查找，找到了有效的物理页框则直接返回，如果没有找到则进行正常的页表访问，页表中找到后则更新 TLB，从 TLB 中淘汰一个表项，然后用新找到的表项替代它，这样下次相同的页面过来时可以直接命中 TLB 找到对应的物理地址，速度更快，不需要继续去访问页表。

这里之所以认为 TLB 能提高速度主要依靠**程序局部性原理**，程序局部性原理是指程序在执行过程中的一个较短时间，所执行的指令地址和要访问的数据通常都局限在一块区域内，这里可分为 `时间局部性` 和 `空间局部性`：

- **时间局部性**：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时间内；
- **空间局部性**：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内。

### 多级页表

通过 TLB 可以加快虚拟地址到物理地址的转换速度，还有个问题，现在都是 64 位操作系统啦，有很大的虚拟地址空间，虚拟地址空间大那对应的页表也会非常大，又加上多个进程多个页表，那计算机的大部分空间就都被拿去存放页表，有没有更好的办法解决页表大的问题呢？答案是**多级页表**。

> 页表为什么大？32 位环境下，虚拟地址空间有 4GB，一个页大小是 4KB，那么整个页表就需要 100 万页，而每个页表项需要 4 个字节，那整个页表就需要 4MB 的内存空间，又因为每个进程都有一个自己的页表，多个进程情况下，这简直就是灾难。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101734466.png)

如图，以一个 32 位虚拟地址的二级页表为例，将 32 位虚拟地址划分为 10 位的 PT1 域，10 位的 PT2 域，以及 12 位的 offset 域，当一个虚拟地址被送入 MMU 时，MMU 首先提取 PT1 域并把其值作为访问第一级页表的索引，之后提取 PT2 域把把其值作为访问第二级页表的索引，之后再根据 offset 找到对应的页框号。

32 位的虚拟地址空间下：每个页面 4KB，且每条页表项占 4B：

- **一级页表**：进程需要 1M 个页表项（4GB / 4KB = 1M, 2^20 个页表项），即页表（每个进程都有一个页表）占用 4MB（1M * 4B = 4MB）的内存空间。
- **二级页表**：一级页表映射 4MB（2^22）、二级页表映射 4KB，则需要 1K 个一级页表项（4GB / 4MB = 1K, 2^10 个一级页表项）、每个一级页表项对应 1K 个二级页表项（4MB / 4KB = 1K），这样页表占用 4.004MB（1K * 4B + 1K * 1K * 4B = 4.004MB）的内存空间。

二级页表占用空间看着貌似变大了，**为什么还说多级页表省内存呢**？

每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，何必去映射不可能用到的空间呢？

也就是说，一级页表覆盖了整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 0.804MB（1K*4B+0.2*1K*1K*4B=0.804MB），对比单级页表的 4M 是不是一个巨大的节约？

**那么为什么不分级的页表就做不到这样节约内存呢**？我们从页表的性质来看，保存在主存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 1M 个页表项来映射，而二级页表则最少只需要 1K 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

二级页表其实可以不在内存中：其实这就像是把页表当成了页面。当需要用到某个页面时，将此页面从磁盘调入到内存；当内存中页面满了时，将内存中的页面调出到磁盘，这是利用到了程序运行的局部性原理。我们可以很自然发现，虚拟内存地址存在着局部性，那么负责映射虚拟内存地址的页表项当然也存在着局部性了！这样我们再来看二级页表，根据局部性原理，1024 个第二级页表中，只会有很少的一部分在某一时刻正在使用，我们岂不是可以把二级页表都放在磁盘中，在需要时才调入到内存？

我们考虑极端情况，只有一级页表在内存中，二级页表仅有一个在内存中，其余全在磁盘中（虽然这样效率非常低），则此时页表占用了 8KB（1K*4B+1*1K*4B=8KB），对比上一步的 0.804MB，占用空间又缩小了好多倍！

## 什么是缺页中断？

缺页中断就是要访问的页不在主存中，需要操作系统将页调入主存后再进行访问，此时会暂时停止指令的执行，产生一个页不存在的异常，对应的异常处理程序就会从选择一页调入到内存，调入内存后之前的异常指令就可以继续执行。

缺页中断的处理过程如下：

1. 如果内存中有空闲的物理页面，则分配一物理页帧 r，然后转第 4 步，否则转第 2 步；
2. 选择某种页面置换算法，选择一个将被替换的物理页帧 r，它所对应的逻辑页为 q，如果该页在内存期间被修改过，则需把它写回到外存；
3. 将 q 所对应的页表项进行修改，把驻留位置 0；
4. 将需要访问的页 p 装入到物理页面 r 中；
5. 修改 p 所对应的页表项的内容，把驻留位置 1，把物理页帧号置为 x；
6. 重新运行被中断的指令。

## **🌟**都有哪些页面置换算法？

当缺页中断发生时，需要调入新的页面到内存中，而内存已满时，选择内存中哪个物理页面被置换是个学问，由此引入了多种页面置换算法，致力于尽可能减少页面的换入换出次数（缺页中断次数）。尽量把未来不再使用的或短期内较少使用的页面换出，通常在程序局部性原理指导下依据过去的统计数据来进行预测。

#### **最优页面置换算法**

当一个缺页中断发生时，对于保存在内存当中的每一个逻辑页面，计算在它的下一次访问之前，还需等待多长时间，从中选择等待时间最长的那个，作为被置换的页面。注意这只是一种**理想情况**，在实际系统中是无法实现的，因为操作系统不可能预测未来，不知道每一个页面要等待多长时间以后才会再次被访问。该算法可用作其它算法的性能评价的依据（在一个模拟器上运行某个程序，并记录每一次的页面访问情况，在第二遍运行时即可使用最优算法）。

#### **先进先出算法**

最先进入的页面最先被淘汰，这种算法很简单，不多介绍。

#### **最近最久未使用算法**

传说中的 LUR 算法，当发生缺页中断时，选择最近最久没有使用过的页面淘汰，该算法会给每个页面一个字段，用于记录自上次访问以来所经历的时间 T，当需要淘汰一个页面时，选择已有页面中 T 值最大的页面进行淘汰。

#### **第二次机会页面置换算法**

先进先出算法的升级版，只是在先进先出算法的基础上做了一点点改动，因为先进先出算法可能会把经常使用的页面置换出去，该方法会给这些页面多一次机会，给页面设置一个修改位 R，每次淘汰最老页面时，检查最老页面的 R 位，如果 R 位是 0，那么代表这个页面又老又没有被二次使用过，直接淘汰，如果这个页面的 R 位是 1，表示该页面被二次访问过，将 R 位置 0，并且把该页面放到链表的尾端，像该页面是最新进来的一样，然后继续按这种方法淘汰最老的页面。

#### **时钟页面置换算法**

第二次机会页面算法的升级版，尽管二次机会页面算法是比较合理的算法，但它需要在链表中经常移动页面，效率比较低，时钟页面置换算法如图，该算法把所有的页面都保存在一个类似时钟的环形链表中，一个表针指向最老的页面，当发生缺页中断时，算法首先检查表针指向的页面，如果它的 R 位是 0 就淘汰该页面，并且把新的页面插入这个位置，然后表针移动到下一个位置，如果 R 位是 1 就将 R 位置 0 并把表针移动到下一个位置，重复这个过程直到找到一个 R 位是 0 的页面然后淘汰。

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101734076.png)

#### **最不常用算法**

当发生缺页中断时，选择访问次数最少的那个页面去淘汰。该算法可以给每个页面设置一个计数器，被访问时，该页面的访问计数器 +1，在需要淘汰时，选择计数器值最小的那个页面。

**这里有个问题**：一个页面如果在开始的时候访问次数很多，但之后就再也不用了，那它可能永远都不会淘汰，但它又确实需要被淘汰，怎么办呢？可以定期把减少各个页面计数器的值，常见的方法是定期将页面计数器右移一位。

最不常用算法（LFU）和最近最久未使用算法（LRU）的区别：LRU 考察的是最久未访问，时间越短越好，而 LFU 考察的是访问的次数或频度，访问次数越多越好。

#### **工作集页面置换算法**

介绍该算法时首先介绍下什么是工作集。

工作集是指一个进程当前正在使用的页面的集合，可以用二元函数 W(t, s)表示：

- t 表示当前的执行时刻）s 表示工作集窗口，表示一个固定的时间段
- W(t, s)表示在当前时刻 t 之前的 s 时间段中所有访问页面所组成的集合

不同时间下的工作集会有所变化，如图：

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101734904.png)

- 进程开始执行后随着访问新页面逐步建立较稳定的工作集
- 当内存访问的局部性区域的位置大致稳定时(只访问那几个页面 没有大的改变时) 工作集大小也大致稳定
- 局部性区域的位置改变时(进程前一项事情做完 去做下一项事情时) 工作集快速扩张和快速收缩过渡到下一个稳定值。

工作集置换算法主要就是换出不在工作集中的页面，示例如图：

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101734681.png)

- 第 0 次访问 e：缺页，装入 e
- 第 1 次访问 d：缺页，装入 d
- 第 2 次访问 a：缺页，装入 a
- 第 3 次访问 c：缺页，装入 c
- 第 4 次访问 c：命中，时间窗口【1-4】，淘汰 e
- 第 5 次访问 d：命中，时间窗口【2-5】
- 第 6 次访问 b：缺页，时间窗口【3-6】，淘汰 a，装入 b
- 第 7 次访问 c：命中，时间窗口【4-7】
- 第 8 次访问 e：缺页，时间窗口【5-8】，装入 e
- 第 9 次访问 c：命中，时间窗口【6-9】，淘汰 d，装入 c
- 第 10 次访问 e：命中，时间窗口【7-10】，淘汰 b
- 第 11 次访问 a：缺页，时间窗口【8-11】，装入 a
- 第 12 次访问 d：缺页，时间窗口【9-12】，装入 d

#### 工作集时钟页面置换算法

在工作集页面置换算法中，当缺页中断发生后，需要扫描整个页表才能直到页面的状态，进而才能确定被淘汰的是哪个页面，因此比较耗时，所以引入了工作集时钟页面算法。与时钟算法改进了先进先出算法类似，工作集页面置换算法 + 时钟算法=工作集时钟页面置换算法。避免了每次缺页中断都需要扫描整个页表的开销。

<table>
    <tr>
    <td>算法名称<br/></td><td>核心思想<br/></td><td>优点<br/></td><td>缺点<br/></td><td>适用场景<br/></td></tr>
    <tr>
    <td> 最优算法(OPT) <br/></td><td>置换未来最长时间不被访问的页面<br/></td><td>理论最优（缺页率最低）<br/></td><td>无法实际实现（需预知未来）<br/></td><td>作为其他算法的性能基准<br/></td></tr>
    <tr>
    <td> 先进先出(FIFO) <br/></td><td>置换最早进入内存的页面<br/></td><td>实现简单<br/></td><td>可能置换高频使用页面（Belady异常）<br/></td><td>早期简单系统<br/></td></tr>
    <tr>
    <td> 最近最久未用(LRU) <br/></td><td>置换最长时间未被访问的页面<br/></td><td>符合局部性原理，性能接近OPT<br/></td><td>硬件实现代价高（需维护访问时间栈）<br/></td><td>对性能要求高的系统<br/></td></tr>
    <tr>
    <td> 第二次机会(SC) <br/></td><td>FIFO改进版，检查页面访问位(R)，若为1则给第二次机会<br/></td><td>减少高频页面被误置换<br/></td><td>链表移动开销大<br/></td><td>需平衡开销的中等复杂度系统<br/></td></tr>
    <tr>
    <td> 时钟算法(Clock) <br/></td><td>环形链表维护页面，指针扫描时清除R位，置换R=0的页面<br/></td><td>降低SC的移动开销<br/></td><td>可能重复扫描<br/></td><td>通用系统（Linux改进版常用）<br/></td></tr>
    <tr>
    <td> 最不常用(LFU) <br/></td><td>置换访问频率最低的页面<br/></td><td>适合长期热点页面明显的场景<br/></td><td>计数器溢出问题，历史权重过高<br/></td><td>长期运行的缓存系统<br/></td></tr>
    <tr>
    <td> 工作集(WS) <br/></td><td>置换不在当前工作集（最近Δ时间内被访问的页面集合）中的页面<br/></td><td>动态适应程序局部性变化<br/></td><td>需维护时间窗口，计算开销大<br/></td><td>多道程序分时系统<br/></td></tr>
    <tr>
    <td> 工作集时钟(WSClock) <br/></td><td>结合工作集和时钟算法，环形扫描时检查是否在工作集窗口内<br/></td><td>避免全表扫描，实时性较好<br/></td><td>实现复杂<br/></td><td>现代通用操作系统（如Windows）<br/></td></tr>
    </table>



## 什么是分段内存管理？

关于分段内存管理我们平时见的最多的应该就是 Linux 可执行程序的代码段数据段之类的啦，要了解分段最好的方式就是了解它的历史。分段起源于 8086CPU，那时候程序访问内存还是直接给出相应单元的物理地址，为了方便多道程序并发执行，需要支持对各个程序进行重定位，如果不支持重定位，涉及到内存访问的地方都需要将地址写死，进而把某个程序加载到物理内存的固定区间。通过分段机制，程序中只需要使用段的相对地址，然后更改段的基址，就方便对程序进行重定位。而且 8086CPU 的地址线宽度是 20 位，可寻址范围可以达到 1MB，但是它们的寄存器都是 16 位，直接使用 1 个 16 位寄存器不可能访存达到 1MB，因此引入了段，引入了段寄存器，段寄存器左移 4 位 + 偏移量就可以生成 20 位的地址，从而达到 1MB 的寻址范围。

以如今的科技水平，其实已经不再需要这种段移位加偏移的方式来访存，分段更多的是一种历史包袱，没有多大实际作用，而且我们经常见到的可执行程序中代码段数据段这些更多是为了在逻辑上能够更清晰有序的构造程序的组织结构。Linux 实际上没有使用分段而只使用了分页管理，这样会更加简单，现在的分段其实更多是为了使逻辑更加清晰。一个公司，为了方便管理都会划分为好多个部门，这其实和分段逻辑相似，没有什么物理意义但是逻辑更加清晰。

## 分页机制和分段机制的共同点和区别

共同点 ：

- 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

区别 ：

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
- 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

# 文件管理篇

## 文件系统的实现

- [https://www.cnblogs.com/cxuanBlog/p/12565601.html](https://www.cnblogs.com/cxuanBlog/p/12565601.html)

## **提高文件系统性能的方式**

访问磁盘的效率要比内存慢很多，是时候又祭出这张图了

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101728825.png)

所以磁盘优化是很有必要的，下面我们会讨论几种优化方式

### **高速缓存**

最常用的减少磁盘访问次数的技术是使用 `块高速缓存(block cache)` 或者 `缓冲区高速缓存(buffer cache)`。高速缓存指的是一系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。

管理高速缓存有不同的算法，常用的算法是：检查全部的读请求，查看在高速缓存中是否有所需要的块。如果存在，可执行读操作而无须访问磁盘。如果检查块不再高速缓存中，那么首先把它读入高速缓存，再复制到所需的地方。之后，对同一个块的请求都通过 `高速缓存` 来完成。

高速缓存的操作如下图所示

![](https://chengxuchu-1301103198.cos.ap-beijing.myqcloud.com/Photo/202505101728241.png)

由于在高速缓存中有许多块，所以需要某种方法快速确定所需的块是否存在。常用方法是将设备和磁盘地址进行散列操作。然后在散列表中查找结果。具有相同散列值的块在一个链表中连接在一起（这个数据结构是不是很像 HashMap?），这样就可以沿着冲突链查找其他块。

如果高速缓存 `已满`，此时需要调入新的块，则要把原来的某一块调出高速缓存，如果要调出的块在上次调入后已经被修改过，则需要把它写回磁盘。这种情况与分页非常相似。

### **块提前读**

第二个明显提高文件系统的性能是**在需要用到块之前试图提前将其写入高速缓存从而提高命中率**。许多文件都是 `顺序读取`。如果请求文件系统在某个文件中生成块 k，文件系统执行相关操作并且在完成之后，会检查高速缓存，以便确定块 k + 1 是否已经在高速缓存。如果不在，文件系统会为 k + 1 安排一个预读取，因为文件希望在用到该块的时候能够直接从高速缓存中读取。

当然，块提前读取策略只适用于实际顺序读取的文件。对随机访问的文件，提前读丝毫不起作用。甚至还会造成阻碍。

### **减少磁盘臂运动**

高速缓存和块提前读并不是提高文件系统性能的唯一方法。另一种重要的技术是**把有可能顺序访问的块放在一起，当然最好是在同一个柱面上，从而减少磁盘臂的移动次数**。当写一个输出文件时，文件系统就必须按照要求一次一次地分配磁盘块。如果用位图来记录空闲块，并且整个位图在内存中，那么选择与前一块最近的空闲块是很容易的。如果用空闲表，并且链表的一部分存在磁盘上，要分配紧邻的空闲块就会困难很多。

不过，即使采用空闲表，也可以使用 `块簇` 技术。即不用块而用连续块簇来跟踪磁盘存储区。如果一个扇区有 512 个字节，有可能系统采用 1 KB 的块（2 个扇区），但却按每 2 块（4 个扇区）一个单位来分配磁盘存储区。这和 2 KB 的磁盘块并不相同，因为在高速缓存中它仍然使用 1 KB 的块，磁盘与内存数据之间传送也是以 1 KB 进行，但在一个空闲的系统上顺序读取这些文件，寻道的次数可以减少一半，从而使文件系统的性能大大改善。若考虑旋转定位则可以得到这类方法的变体。在分配块时，系统尽量把一个文件中的连续块存放在同一个柱面上。

在使用 inode 或任何类似 inode 的系统中，另一个性能瓶颈是，读取一个很短的文件也需要两次磁盘访问：**一次是访问 inode，一次是访问块**。通常情况下，inode 的放置如下图所示

其中，全部 inode 放在靠近磁盘开始位置，所以 inode 和它所指向的块之间的平均距离是柱面组的一半，这将会需要较长时间的寻道时间。

一个简单的改进方法是，在磁盘中部而不是开始处存放 inode ，此时，在 inode 和第一个块之间的寻道时间减为原来的一半。另一种做法是：将磁盘分成多个柱面组，每个柱面组有自己的 inode，数据块和空闲表，如上图 b 所示。

当然，只有在磁盘中装有磁盘臂的情况下，讨论寻道时间和旋转时间才是有意义的。现在越来越多的电脑使用 `固态硬盘(SSD)`，对于这些硬盘，由于采用了和闪存同样的制造技术，使得随机访问和顺序访问在传输速度上已经较为相近，传统硬盘的许多问题就消失了。但是也引发了新的问题。

### **磁盘碎片整理**

在初始安装操作系统后，文件就会被不断的创建和清除，于是磁盘会产生很多的碎片，在创建一个文件时，它使用的块会散布在整个磁盘上，降低性能。删除文件后，回收磁盘块，可能会造成空穴。

磁盘性能可以通过如下方式恢复：移动文件使它们相互挨着，并把所有的至少是大部分的空闲空间放在一个或多个大的连续区域内。Windows 有一个程序 `defrag` 就是做这个事儿的。Windows 用户会经常使用它，SSD 除外。

磁盘碎片整理程序会在让文件系统上很好地运行。Linux 文件系统（特别是 ext2 和 ext3）由于其选择磁盘块的方式，在磁盘碎片整理上一般不会像 Windows 一样困难，因此很少需要手动的磁盘碎片整理。而且，固态硬盘并不受磁盘碎片的影响，事实上，在固态硬盘上做磁盘碎片整理反倒是多此一举，不仅没有提高性能，反而磨损了固态硬盘。所以碎片整理只会缩短固态硬盘的寿命。

## 磁盘调度算法

- 先来先服务
- 最短寻道时间：磁盘接收到读命令之后，磁头从当前位置移动到目标位置，所需时间为寻道时间，这个算法就是选择与当前磁头所在轨道距离最近的请求作为下一次服务对象。
- 扫描算法：在磁头的当前移动方向上，找到离磁头最近的磁道
- 循环扫描：规定磁头的单向移动，进行循环扫描

## **RAID 的不同级别**

RAID 称为 `磁盘冗余阵列`，简称 `磁盘阵列`。利用虚拟化技术把多个硬盘结合在一起，成为一个或多个磁盘阵列组，目的是提升性能或数据冗余。

RAID 有不同的级别

- RAID 0 - 无容错的条带化磁盘阵列
- RAID 1 - 镜像和双工
- RAID 2 - 内存式纠错码
- RAID 3 - 比特交错奇偶校验
- RAID 4 - 块交错奇偶校验
- RAID 5 - 块交错分布式奇偶校验
- RAID 6 - P + Q 冗余

# 设备管理篇

设备控制器：位于 CPU 和 I/O 之间，其接收来自 CPU 的指令，并控制 I/O 设备。

## **🌟**I/O 控制方式

1. 程序直接控制方式：向 CPU 和 I/O 设备设备控制器发出命令之后，然后就需要一直检测状态寄存器的值，判断是否结束任务，结束之后再去执行下一个任务。
2. 中断控制方式：当 CPU 向设备控制器发出启动指令后，则去做其他工作，设备控制器完成任务后，则会发送一个中断指令，告诉他，我已经完成任务了，然后让其继续回来处理任务。但是这样也存在问题，中断过多的话，则会耗费大量 CPU 时间。
3. DMA 控制方式：数据传输的基本单位是块，然后传输过程是 DMA 控制器直接于内存交换，仅在传送一个或多个块的开始或结束时，才需 CPU 干预。中断控制方式在每个数据传输完之后中断 CPU，DMA 是一批数据全部传输完才进行中断。
4. 通道控制方式：通道控制方式和 DMA 类似，但是所需要的 CPU 干预更少，我们可以将他理解成一个简单的控制器，代理 CPU 进行处理。

<table>
    <tr>
    <td>控制方式<br/></td><td>数据传输单位<br/></td><td>CPU干预频率<br/></td><td>硬件复杂度<br/></td><td>主要优点<br/></td><td>主要缺点<br/></td><td>典型应用场景<br/></td></tr>
    <tr>
    <td> 程序直接控制 <br/></td><td>字节/字<br/></td><td>全程参与<br/></td><td>低<br/></td><td>实现简单<br/></td><td>CPU利用率极低（忙等待）<br/></td><td>早期嵌入式设备<br/></td></tr>
    <tr>
    <td> 中断控制 <br/></td><td>字节/字<br/></td><td>每次传输后中断<br/></td><td>中<br/></td><td>支持多任务并行<br/></td><td>高频中断导致CPU开销大<br/></td><td>鼠标、键盘等低速设备<br/></td></tr>
    <tr>
    <td> DMA控制 <br/></td><td>数据块<br/></td><td>整块传输开始/结束时<br/></td><td>高<br/></td><td>大幅减少CPU干预<br/></td><td>需要专用DMA控制器<br/></td><td>磁盘、网卡等高速设备<br/></td></tr>
    <tr>
    <td> 通道控制 <br/></td><td>数据块组<br/></td><td>仅需初始化和结束时<br/></td><td>最高<br/></td><td>近乎完全解放CPU<br/></td><td>需要复杂通道处理器<br/></td><td>大型机、高性能存储系统<br/></td></tr>
    </table>



### 关键特性对比

<table>
    <tr>
    <td>维度<br/></td><td>程序直接控制<br/></td><td>中断控制<br/></td><td>DMA控制<br/></td><td>通道控制<br/></td></tr>
    <tr>
    <td> 数据流向 <br/></td><td>CPU↔设备<br/></td><td>CPU↔设备<br/></td><td>设备↔内存<br/></td><td>设备↔内存<br/></td></tr>
    <tr>
    <td> 并行能力 <br/></td><td>无<br/></td><td>有限<br/></td><td>较强<br/></td><td>强<br/></td></tr>
    <tr>
    <td> 硬件成本 <br/></td><td>几乎为零<br/></td><td>低<br/></td><td>中等（DMA芯片）<br/></td><td>高（通道处理器）<br/></td></tr>
    <tr>
    <td> 传输效率 <br/></td><td>极低<br/></td><td>低-中<br/></td><td>高<br/></td><td>极高<br/></td></tr>
    <tr>
    <td> 典型延迟 <br/></td><td>微秒级<br/></td><td>毫秒级<br/></td><td>纳秒级<br/></td><td>纳秒级<br/></td></tr>
    </table>


## I/O 软件的层次结构

## I/O 子系统

I/O 核心子系统是设备控制的各类方法，其提供的主要服务就是 `I/O调度`，`高速缓存与缓冲区`、`设备分配与回收`、`假脱机`。

`I/O调度`：就是确定一个好的顺序来执行 I/O 请求。因为应用程序所发布系统调用顺序不一定总是最佳选择，所以需要通过调度来改善系统的整体性能。主要是通过重新安排任务队列顺序以改善系统总体调用。

`引入缓存`：引入缓冲后可以降低设备对 CPU 的中断频率，放宽对中断响应时间的限制。

缓存的分类

- 单缓存
- 双缓存：可以交替使用，提高并行速度
- 循环缓存

## 假脱机技术

这个是经常用到的，我们系统中有一些独占设备，然后某个进程获得了独占设备的使用权，但是却不经常使用，却又卡着让别人用不了，这就造成了资源的浪费，所以我们将独占设备改造成共享设备，提高利用率。

主要原理是，利用输入缓冲区，输入井，输出缓冲区，输出井来完成。

## **操作系统中的时钟是什么**

`时钟(Clocks)` 也被称为 `定时器(timers)`，时钟/定时器对任何程序系统来说都是必不可少的。时钟负责维护时间、防止一个进程长期占用 CPU 时间等其他功能。`时钟软件(clock software)` 也是一种设备驱动的方式。下面我们就来对时钟进行介绍，一般都是先讨论硬件再介绍软件，采用由下到上的方式，也是告诉你，底层是最重要的。

### **时钟硬件**

在计算机中有两种类型的时钟，这些时钟与现实生活中使用的时钟完全不一样。

- 比较简单的一种时钟被连接到 110 V 或 220 V 的电源线上，这样每个 `电压周期` 会产生一个中断，大概是 50 - 60 HZ。这些时钟过去一直占据支配地位。
- 另外的一种时钟由晶体振荡器、计数器和寄存器组成，示意图如下所示

![](/Users/chef/Documents/team_project/my_project/my_web/src/1-interview_base/04-%25E6%2593%258D%25E4%25BD%259C%25E7%25B3%25BB%25E7%25BB%259F/static/BYgubkHFuorSTYxO268c13lJntc.png)

这种时钟称为 `可编程时钟` ，可编程时钟有两种模式，一种是 `一键式(one-shot mode)`，当时钟启动时，会把存储器中的值复制到计数器中，然后，每次晶体的振荡器的脉冲都会使计数器 -1。当计数器变为 0 时，会产生一个中断，并停止工作，直到软件再一次显示启动。还有一种模式是 `方波(square-wave mode)` 模式，在这种模式下，当计数器变为 0 并产生中断后，存储寄存器的值会自动复制到计数器中，这种周期性的中断称为一个时钟周期。

## **设备控制器的主要功能**

设备控制器是一个 `可编址` 的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；如果设备控制器控制多个可连接设备时，则应含有多个设备地址，并使每一个设备地址对应一个设备。

设备控制器主要分为两种：字符设备和块设备

设备控制器的主要功能有下面这些

- 接收和识别命令：设备控制器可以接受来自 CPU 的指令，并进行识别。设备控制器内部也会有寄存器，用来存放指令和参数
- 进行数据交换：CPU、控制器和设备之间会进行数据的交换，CPU 通过总线把指令发送给控制器，或从控制器中并行地读出数据；控制器将数据写入指定设备。
- 地址识别：每个硬件设备都有自己的地址，设备控制器能够识别这些不同的地址，来达到控制硬件的目的，此外，为使 CPU 能向寄存器中写入或者读取数据，这些寄存器都应具有唯一的地址。
- 差错检测：设备控制器还具有对设备传递过来的数据进行检测的功能。

## **什么是 DMA**

DMA 的中文名称是 `直接内存访问`，它意味着 CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存。也就是 DMA 可以不需要 CPU 的参与。这个过程由称为 DMA 控制器（DMAC）的芯片管理。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。

## **直接内存访问的特点**

DMA 方式有如下特点：

- 数据传送以数据块为基本单位
- 所传送的数据从设备直接送入主存，或者从主存直接输出到设备上
- 仅在传送一个或多个数据块的开始和结束时才需 CPU 的干预，而整块数据的传送则是在控制器的控制下完成。

DMA 方式和中断驱动控制方式相比，减少了 CPU 对 I/O 操作的干预，进一步提高了 CPU 与 I/O 设备的并行操作程度。

DMA 方式的线路简单、价格低廉，适合高速设备与主存之间的成批数据传送，小型、微型机中的快速设备均采用这种方式，但其功能较差，不能满足复杂的 I/O 要求。

# 其它补充

## Linux 的同步机制

## **🌟**I/O 多路复用

- 边缘触发
- 水平触发

## **🌟**大端序小端序

## **🌟**零拷贝

## BIO（同步阻塞）、NIO（同步非阻塞）、AIO（异步非阻塞）

- BIO 堵塞 IO：发现被使用，则一直等待
- NIO：发现被使用，先去干别的，然后每隔一段时间再回来，然后看看用完没。
- AIO：发现被使用，先去干别的，等结束了我通知你，你再回来

## 并发和并行的区别

- 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核 cpu 上的多任务。但是从微观上看两个程序的指令是交织着运行的，指令之间交错执行，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率（如降低某个进程的相应时间）。
- 并行（parallelism）：指严格物理意义上的同时运行，比如多核 cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的 cpu 都是往多核方面发展。

## 什么是信号

一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。 Linux 系统上支持的 30 种不同类型的信号。 每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。

1. 发送信号：内核通过更新目的进程上下文中的某个状态，发送（递送）一个信号给目的进程。发送信号可以有如下两种原因：

   - 内核检测到一个系统事件，比如除零错误或者子进程终止。
   - —个进程调用了 kill 函数， 显式地要求内核发送一个信号给目的进程。一个进程可以发送信号给它自己。
2. 接收信号：当目的进程被内核强迫以某种方式对信号的发送做出反应时，它就接收了信号。进程可以忽略这个信号，终止或者通过执行一个称为信号处理程序(signal handler)的用户层函数捕获这个信号。

## 操作系统中用到了什么排序算法

进程调度：堆排序

文件系统排序：快速排序/归并排序

I/O 调度算法：插入排序/归并排序

内存管理：基数排序（变种）

网络协议栈：计数排序应用

## 了解的 I/O 模型有哪些

<table>
<tr>
<td>I/O 模型<br/></td><td>阻塞？<br/></td><td>同步？<br/></td><td>核心机制<br/></td><td>适用场景<br/></td></tr>
<tr>
<td>阻塞 I/O<br/></td><td>是<br/></td><td>同步<br/></td><td>线程全程等待<br/></td><td>简单低并发程序<br/></td></tr>
<tr>
<td>非阻塞 I/O<br/></td><td>否<br/></td><td>同步<br/></td><td>线程轮询检查<br/></td><td>需兼顾其他任务的程序<br/></td></tr>
<tr>
<td>I/O 多路复用<br/></td><td>是*<br/></td><td>同步<br/></td><td>`select`/`epoll` 监听<br/></td><td>高并发网络服务<br/></td></tr>
</table>


注：I/O 多路复用中，`select`/`epoll` 调用本身是阻塞的，但可监听多个 I/O。

- 阻塞 I/O

  - 调用 I/O 操作时，线程一直等待，直到数据就绪或操作完成。
  - 期间线程无法执行其他任务（CPU 闲置）。
- 非阻塞 I/O

  - 调用 I/O 操作时，若数据未就绪，​立即返回错误​（如 `EWOULDBLOCK`）。
  - 线程需轮询检查数据是否就绪（消耗 CPU）。
  - 线程可执行其他任务（但需主动轮询）。
- I/O 多路复用

  - 使用 `select`/`poll`/`epoll` 等系统调用，​单线程监听多个 I/O 事件。
  - 当某个 I/O 就绪时，通知线程处理。

## 常见的 I/O 多路复用机制

### **select**

- **跨平台**：支持所有主流操作系统（Linux/Windows/macOS）。
- **基于轮询**：通过遍历文件描述符集合（`fd_set`）检查就绪状态。
- **限制**：

  - 单个进程最多监听 **1024** 个文件描述符（FD）。
  - 每次调用需**全量拷贝** `fd_set` 到内核。

```c
fd_set read_fds;
FD_ZERO(&read_fds);
FD_SET(fd1, &read_fds);  _// 添加监听 fd_
int ret = select(fd1 + 1, &read_fds, NULL, NULL, NULL);  _// 阻塞等待_
if (FD_ISSET(fd1, &read_fds)) { _/* 处理就绪的 fd */_ }
```

- **缺点**
  - O(n) 时间复杂度：每次遍历所有 FD，性能随 FD 数量线性下降。
  - 重复初始化：每次调用需重新设置 `fd_set`。

### **poll**

- 改进 `select` 的 FD 数量限制，使用**链表**存储 FD（理论无上限）。
- 仍需要**遍历所有 FD** 检查就绪状态（O(n) 时间复杂度）。

```c
struct pollfd fds[2];
fds[0].fd = fd1; fds[0].events = POLLIN;
int ret = poll(fds, 2, timeout);  _// 阻塞等待_
if (fds[0].revents & POLLIN) { _/* 处理就绪的 fd */_ }
```

**对比 ****select**

<table>
    <tr>
    <td> 特性 <br/></td><td> select <br/></td><td> poll <br/></td></tr>
    <tr>
    <td>FD 数量<br/></td><td>1024（硬编码）<br/></td><td>无限制（受内存约束）<br/></td></tr>
    <tr>
    <td>性能<br/></td><td>O(n)<br/></td><td>O(n)<br/></td></tr>
    <tr>
    <td>编程复杂度<br/></td><td>需手动管理 fd_set<br/></td><td>结构体更清晰<br/></td></tr>
    </table>



### ****epoll****（Linux 专属）​

- **事件驱动**：内核通过**回调机制**直接通知就绪的 FD，无需遍历（O(1) 时间复杂度）。
- **高效内存**：使用**红黑树**管理 FD，支持**水平触发（LT）​**和**边缘触发（ET）​**模式。

**核心函数**

- `epoll_create()`：创建 epoll 实例。
- `epoll_ctl()`：添加/修改/删除监听的 FD。
- `epoll_wait()`：等待就绪事件。

```c
int epfd = epoll_create1(0);
struct epoll_event ev, events[10];
ev.events = EPOLLIN; ev.data.fd = fd1;
epoll_ctl(epfd, EPOLL_CTL_ADD, fd1, &ev);  _// 注册 fd_

int ret = epoll_wait(epfd, events, 10, timeout);  _// 等待事件_

for (int i = 0; i < ret; i++) { _/* 处理 events[i] */_ }
```

**触发模式**

- 水平触发：只要 FD 可读/可写，epoll_wait() 会持续通知（默认模式，类似 poll）。
- 边沿触发：仅在 FD 状态变化时通知一次（需一次性处理完数据，否则可能丢失事件）。

**优点**

- 高性能：支持百万级并发（如 Nginx、Redis）。
- 低开销：无需每次调用传递所有 FD。

### **kqueue**（FreeBSD/macOS 专属）​

- 类似 `epoll`，但使用**事件队列**机制，支持更多事件类型（如文件修改、信号）。
- 代码复杂度较高，但功能更强大。

```c
struct kevent ev, events[10];
int kq = kqueue();
EV_SET(&ev, fd1, EVFILT_READ, EV_ADD, 0, 0, NULL);
kevent(kq, &ev, 1, NULL, 0, NULL);  _// 注册 fd_
int ret = kevent(kq, NULL, 0, events, 10, &timeout);  _// 等待事件_
```

对比 epoll

<table>
    <tr>
    <td> 特性 <br/></td><td> epoll <br/></td><td> kqueue <br/></td></tr>
    <tr>
    <td>平台<br/></td><td>Linux<br/></td><td>FreeBSD/macOS<br/></td></tr>
    <tr>
    <td>事件类型<br/></td><td>网络 I/O 为主<br/></td><td>支持文件、信号等<br/></td></tr>
    <tr>
    <td>性能<br/></td><td>O(1)<br/></td><td>O(1)<br/></td></tr>
    </table>



### **IOCP**（Windows 专属）

- 基于**异步 I/O** 的多路复用模型，与 `epoll`/`kqueue` 设计哲学不同。
- 需配合**完成端口（Completion Port）​**使用，适合高吞吐场景。
- 线程池从完成端口获取已完成的 I/O 操作，而非主动监听 FD。

### **总结对比**

<table>
<tr>
<td>机制<br/></td><td>平台支持<br/></td><td>时间复杂度<br/></td><td>最大并发量<br/></td><td>编程复杂度<br/></td></tr>
<tr>
<td>`select`<br/></td><td>跨平台<br/></td><td>O(n)<br/></td><td>1024<br/></td><td>低<br/></td></tr>
<tr>
<td>`poll`<br/></td><td>跨平台<br/></td><td>O(n)<br/></td><td>无硬限制<br/></td><td>中<br/></td></tr>
<tr>
<td>`epoll`<br/></td><td>Linux<br/></td><td>O(1)<br/></td><td>百万级<br/></td><td>高<br/></td></tr>
<tr>
<td>`kqueue`<br/></td><td>FreeBSD/macOS<br/></td><td>O(1)<br/></td><td>百万级<br/></td><td>高<br/></td></tr>
<tr>
<td>`IOCP`<br/></td><td>Windows<br/></td><td>O(1)<br/></td><td>百万级<br/></td><td>极高<br/></td></tr>
</table>

